Building Function:
def build_SeparatedEASYmodel(input_shape1, input_shape2, input_shape3):
    # First input branch
    input1 = Input(shape=input_shape1, name='input1')
    x1 = Conv1D(128, kernel_size=40, strides=8, activation='relu', name='conv1d_1_1')(input1)
    #x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_1')(x1)
    x1 = Conv1D(128, kernel_size=20, strides=2, activation='relu', name='conv1d_1_2')(x1)
    x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_2')(x1)
    x1 = Conv1D(256, kernel_size=4, activation='relu', name='conv1d_1_3')(x1)
    x1 = GlobalMaxPooling1D(name='globalmaxpool1d_1_1')(x1)
    #x1 = Dense(128, activation='relu', name='dense_1_1')(x1)
    x1 = Dropout(0.2, name='dropout_1_1')(x1)
    out1 = Dense(64, activation='relu', name='dense_1_2')(x1)

    # Second input branch
    input2 = Input(shape=input_shape2, name='input2')
    x2 = Conv1D(128, kernel_size=2, activation='relu', name='conv1d_2_1')(input2)
    #x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_1')(x2)
    x2 = Conv1D(64, kernel_size=8, strides=2, activation='relu', name='conv1d_2_2')(x2)
    x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_2')(x2)
    x2 = Conv1D(128, kernel_size=4, activation='relu', name='conv1d_2_3')(x2)
    x2 = Conv1D(64, kernel_size=2, activation='relu', name='conv1d_2_4')(x2)
    x2 = GlobalMaxPooling1D(name='globalmaxpool1d_2_1')(x2)
    x2 = Dropout(0.2, name='dropout_2_1')(x2)
    out2 = Dense(64, activation='relu', name='dense_2_1')(x2)

    # Third input branch
    input3 = Input(shape=input_shape3, name='input3')
    x3 = Conv1D(64, kernel_size=40, strides=10, activation='relu', name='conv1d_3_1')(input3)
    x3 = MaxPooling1D(pool_size=2, name='maxpool1d_3_1')(x3)
    x3 = Conv1D(64, kernel_size=10, activation='relu', name='conv1d_3_2')(x3)
    # x3 = MaxPooling1D(pool_size=2, name='maxpool1d_3_2')(x3)
    # x3 = Flatten(name='flatten_3_1')(x3)
    x3 = GlobalMaxPooling1D(name = 'globalmaxpool1d_3_1')(x3)
    out3 = Dense(64, activation='relu', name='dense_3_1')(x3)

    # Concatenate the outputs of the branches
    merged = concatenate([out1, out2, out3], name='concatenate_1')
    merged = Dropout(0.25, name='dropout_merged')(merged)
    merged = Dense(64, activation='relu', name='dense_merged_1')(merged)
    output = Dense(1, activation='sigmoid', name='output')(merged)

    # Create the model
    separated_model = Model(inputs=[input1, input2, input3], outputs=output)

    return separated_model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = np.dstack((data[:, :, 0], data[:, :, 2]))
        globals()[f"{key}2"] = np.dstack((data[:, :, 3],))
        globals()[f"{key}3"] = np.dstack((data[:, :, 2], data[:, :, 0]))
        # Uncomment and modify the line below if you need the fourth set
        # globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional_14"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input2 (InputLayer) │ (None, 800, 1)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input1 (InputLayer) │ (None, 800, 2)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 799, 128)  │        384 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 96, 128)   │     10,368 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 396, 64)   │     65,600 │ conv1d_2_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 39, 128)   │    327,808 │ conv1d_1_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_2_2       │ (None, 198, 64)   │          0 │ conv1d_2_2[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 800, 2)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_1_2       │ (None, 19, 128)   │          0 │ conv1d_1_2[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 195, 128)  │     32,896 │ maxpool1d_2_2[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 77, 64)    │      5,184 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 16, 256)   │    131,328 │ maxpool1d_1_2[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_4 (Conv1D) │ (None, 194, 64)   │     16,448 │ conv1d_2_3[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_3_1       │ (None, 38, 64)    │          0 │ conv1d_3_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ globalmaxpool1d_1_1 │ (None, 256)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ globalmaxpool1d_2_1 │ (None, 64)        │          0 │ conv1d_2_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 29, 64)    │     41,024 │ maxpool1d_3_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 256)       │          0 │ globalmaxpool1d_… │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 64)        │          0 │ globalmaxpool1d_… │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ globalmaxpool1d_3_1 │ (None, 64)        │          0 │ conv1d_3_2[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1_2 (Dense)   │ (None, 64)        │     16,448 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2_1 (Dense)   │ (None, 64)        │      4,160 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_3_1 (Dense)   │ (None, 64)        │      4,160 │ globalmaxpool1d_… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 192)       │          0 │ dense_1_2[0][0],  │
│ (Concatenate)       │                   │            │ dense_2_1[0][0],  │
│                     │                   │            │ dense_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_merged      │ (None, 192)       │          0 │ concatenate_1[0]… │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_merged_1      │ (None, 64)        │     12,352 │ dropout_merged[0… │
│ (Dense)             │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 1)         │         65 │ dense_merged_1[0… │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,004,677 (7.65 MB)
 Trainable params: 668,225 (2.55 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,336,452 (5.10 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7fca04eb7610>
Loss Function: binary_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.10819035768508911
Test val_loss: 0.19731290638446808
Train accuracy: 0.9556313753128052
Accuracy Score: 0.9522184300341296
F1 Score: 0.9567901234567902
Classification Report:
               precision    recall  f1-score   support

         0.0       0.94      0.95      0.95       130
         1.0       0.96      0.95      0.96       163

    accuracy                           0.95       293
   macro avg       0.95      0.95      0.95       293
weighted avg       0.95      0.95      0.95       293

Training History:
accuracy: [0.5893060564994812, 0.7485779523849487, 0.7474402785301208, 0.7690557241439819, 0.7713310718536377, 0.7827076315879822, 0.8054607510566711, 0.8134243488311768, 0.8384528160095215, 0.8156996369361877, 0.8475540280342102, 0.8361774682998657, 0.8600682616233826, 0.8532423377037048, 0.8748577833175659, 0.8805460929870605, 0.8896473050117493, 0.9021615386009216, 0.8885096907615662, 0.9112628102302551, 0.9135380983352661, 0.9101251363754272, 0.9249146580696106, 0.9260523319244385, 0.9260523319244385, 0.9271900057792664, 0.9237770438194275, 0.9465301632881165, 0.935153603553772, 0.9306029677391052, 0.9453924894332886, 0.9510807991027832, 0.9453924894332886, 0.9442548155784607, 0.9328782558441162, 0.9419795274734497, 0.9533560872077942, 0.9476677775382996, 0.9533560872077942, 0.9556313753128052, 0.9476677775382996, 0.9567690491676331, 0.9590443968772888, 0.9647326469421387, 0.9681456089019775, 0.9579067230224609, 0.9067121744155884, 0.939704179763794, 0.9510807991027832, 0.9635949730873108, 0.9556313753128052]
loss: [0.6908745169639587, 0.5154749751091003, 0.5372220277786255, 0.4723843038082123, 0.4669326841831207, 0.4400586187839508, 0.41285440325737, 0.3857080042362213, 0.36854761838912964, 0.37840142846107483, 0.34645745158195496, 0.3649846017360687, 0.3166045844554901, 0.31247836351394653, 0.30575117468833923, 0.25982001423835754, 0.2720840871334076, 0.23909419775009155, 0.26023805141448975, 0.22438807785511017, 0.2167748063802719, 0.20710352063179016, 0.20389150083065033, 0.18739941716194153, 0.17842964828014374, 0.19168581068515778, 0.1850920170545578, 0.15169601142406464, 0.15540605783462524, 0.1538538634777069, 0.13653461635112762, 0.13732917606830597, 0.13536348938941956, 0.13451410830020905, 0.16839976608753204, 0.13773521780967712, 0.1348322629928589, 0.1295667588710785, 0.12557730078697205, 0.1023428663611412, 0.17040394246578217, 0.11006354540586472, 0.109364353120327, 0.09350694715976715, 0.08550088852643967, 0.11476316303014755, 0.21011756360530853, 0.15125368535518646, 0.12530341744422913, 0.09515201300382614, 0.10819035768508911]
val_accuracy: [0.7713310718536377, 0.7918089032173157, 0.7201365232467651, 0.7747440338134766, 0.788395881652832, 0.8259385824203491, 0.8156996369361877, 0.8156996369361877, 0.8464163541793823, 0.8464163541793823, 0.8634812235832214, 0.8634812235832214, 0.8771331310272217, 0.8361774682998657, 0.894197940826416, 0.873720109462738, 0.9010238647460938, 0.8771331310272217, 0.894197940826416, 0.8873720169067383, 0.9112628102302551, 0.8976109027862549, 0.9112628102302551, 0.9112628102302551, 0.9215016961097717, 0.8771331310272217, 0.9078498482704163, 0.914675772190094, 0.914675772190094, 0.9010238647460938, 0.914675772190094, 0.9215016961097717, 0.9249146580696106, 0.9010238647460938, 0.9044368863105774, 0.9180887341499329, 0.9283276200294495, 0.9180887341499329, 0.935153603553772, 0.914675772190094, 0.9215016961097717, 0.9283276200294495, 0.9283276200294495, 0.9283276200294495, 0.9283276200294495, 0.9180887341499329, 0.914675772190094, 0.9112628102302551, 0.9180887341499329, 0.9249146580696106, 0.935153603553772]
val_loss: [0.5901726484298706, 0.385079950094223, 0.5224207043647766, 0.45212292671203613, 0.4541478455066681, 0.3629063367843628, 0.4047093689441681, 0.34597247838974, 0.3432599902153015, 0.3158518373966217, 0.29354697465896606, 0.3086126148700714, 0.28285151720046997, 0.32212674617767334, 0.2573525011539459, 0.266987681388855, 0.24488210678100586, 0.38861820101737976, 0.25627246499061584, 0.26492783427238464, 0.22659333050251007, 0.22837617993354797, 0.2445218414068222, 0.2659513056278229, 0.2379184514284134, 0.2798371911048889, 0.23657439649105072, 0.23829033970832825, 0.21880260109901428, 0.2919345796108246, 0.21151861548423767, 0.22541673481464386, 0.2242821902036667, 0.25524449348449707, 0.21408383548259735, 0.24080415070056915, 0.22322681546211243, 0.23435598611831665, 0.18377651274204254, 0.24771668016910553, 0.2515299916267395, 0.19902123510837555, 0.18525242805480957, 0.19371956586837769, 0.20459680259227753, 0.23703281581401825, 0.23364296555519104, 0.25550004839897156, 0.23300909996032715, 0.20563624799251556, 0.19731290638446808]

Confusion Matrix:
[[124   6]
 [  8 155]]

################################################################################################ 

