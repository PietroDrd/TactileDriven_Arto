def build_SeparatedEASYmodel(F_input_shape, P_input_shape):
    force_input = Input(shape=F_input_shape, name='force_input')
    Fbranch = Sequential()
    Fbranch.add(Conv1D(64, kernel_size=40, strides=10, activation='relu', input_shape=F_input_shape))
    Fbranch.add(MaxPooling1D(pool_size=2))
    Fbranch.add(Conv1D(128, kernel_size=10, activation='relu'))
    Fbranch.add(MaxPooling1D(pool_size=2))
    Fbranch.add(Conv1D(256, kernel_size=2, activation='relu'))
    Fbranch.add(GlobalMaxPooling1D())
    Fbranch.add(Flatten())
    Fbranch.add(Dense(32, activation='relu'))
    outF = Fbranch(force_input)
    
    # pose_input = Input(shape=F_input_shape, name='pose_input')
    # Pbranch = Sequential()
    # Pbranch.add(Conv1D(64, kernel_size=60, activation='relu', input_shape=P_input_shape))
    # Pbranch.add(MaxPooling1D(pool_size=2))
    # Pbranch.add(Conv1D(64, kernel_size=10, activation='relu'))
    # Pbranch.add(MaxPooling1D(pool_size=2))
    # Pbranch.add(Flatten())
    # Pbranch.add(Dense(32, activation='relu'))
    # outP = Pbranch(pose_input)


    pose_input = Input(shape=F_input_shape, name='pose_input')
    Pbranch = Sequential()
    Pbranch.add(Conv1D(64, kernel_size=40, strides=10, activation='relu', input_shape=P_input_shape))
    Pbranch.add(MaxPooling1D(pool_size=2))
    Pbranch.add(Conv1D(64, kernel_size=10, activation='relu'))
    Pbranch.add(MaxPooling1D(pool_size=2))
    Pbranch.add(Flatten())
    Pbranch.add(Dense(16, activation='relu'))
    outP = Pbranch(pose_input)
    
    merged = concatenate([outF, outP])
    merged = Dense(64, activation='relu')(merged)
    merged = Dense(1, activation='sigmoid')(merged)
    separated_model = Model(inputs=[force_input, pose_input], outputs=merged)
    
    return separated_model

Model: "functional_667"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ force_input         │ (None, 800, 1)    │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pose_input          │ (None, 800, 1)    │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ sequential_82       │ (None, 32)        │    158,688 │ force_input[0][0] │
│ (Sequential)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ sequential_83       │ (None, 16)        │     63,120 │ pose_input[0][0]  │
│ (Sequential)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_24      │ (None, 48)        │          0 │ sequential_82[0]… │
│ (Concatenate)       │                   │            │ sequential_83[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_159 (Dense)   │ (None, 64)        │      3,136 │ concatenate_24[0… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_160 (Dense)   │ (None, 1)         │         65 │ dense_159[0][0]   │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 675,029 (2.58 MB)
 Trainable params: 225,009 (878.94 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 450,020 (1.72 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adamw.AdamW object at 0x7d228fab9960>
Loss Function: binary_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adamw/learning_rate>

Train loss: 0.1957821100950241
Test val_loss: 0.2806391716003418
Train accuracy: 0.9211229681968689
Accuracy Score: 0.936
F1 Score: 0.9344262295081968
Classification Report:
               precision    recall  f1-score   support

         0.0       0.94      0.93      0.94       129
         1.0       0.93      0.94      0.93       121

    accuracy                           0.94       250
   macro avg       0.94      0.94      0.94       250
weighted avg       0.94      0.94      0.94       250

Training History:
accuracy: [0.5748662948608398, 0.6898396015167236, 0.7219251394271851, 0.7326202988624573, 0.7540106773376465, 0.7780748605728149, 0.8155080080032349, 0.8155080080032349, 0.8502673506736755, 0.8395721912384033, 0.866310179233551, 0.8917112350463867, 0.8997326493263245, 0.8997326493263245, 0.9064171314239502, 0.9064171314239502, 0.9304812550544739, 0.9211229681968689]
loss: [0.6777721047401428, 0.6039007902145386, 0.5538492202758789, 0.5163311958312988, 0.48110517859458923, 0.44732093811035156, 0.3929433524608612, 0.3849889636039734, 0.32984504103660583, 0.31522634625434875, 0.3001782298088074, 0.27201202511787415, 0.2490161806344986, 0.22513139247894287, 0.21911388635635376, 0.21336641907691956, 0.1623227447271347, 0.1957821100950241]
val_accuracy: [0.656000018119812, 0.6800000071525574, 0.656000018119812, 0.7400000095367432, 0.7400000095367432, 0.8159999847412109, 0.7919999957084656, 0.8679999709129333, 0.8320000171661377, 0.8679999709129333, 0.8920000195503235, 0.8560000061988831, 0.9039999842643738, 0.8360000252723694, 0.8759999871253967, 0.9279999732971191, 0.9240000247955322, 0.9039999842643738]
val_loss: [0.6433651447296143, 0.6023388504981995, 0.616772472858429, 0.5090708136558533, 0.5293359160423279, 0.407059907913208, 0.464959979057312, 0.3635813295841217, 0.35179242491722107, 0.3232913017272949, 0.31102582812309265, 0.38666731119155884, 0.27987614274024963, 0.38118669390678406, 0.32981184124946594, 0.24656760692596436, 0.24290286004543304, 0.2806391716003418]

################################################################################################ 

