Building Function:
def build_branched_model1(input_shape1, input_shape2, input_shape3):
    # First input branch
    input1 = Input(shape=input_shape1, name='input1')
    x1 = Conv1D(filters=128, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_1_1')(input1)
    # x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_1')(x1)
    x1 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_1_2')(x1)
    x1 = Dropout(rate=0.2, name='dropout_1_1')(x1)
    x1 = Conv1D(filters=256, kernel_size=2, strides=1, activation='relu', name='conv1d_1_3')(x1)
    x1 = GlobalMaxPooling1D(name='gap1d_1_1')(x1)
    
    # Second input branch
    input2 = Input(shape=input_shape2, name='input2')
    x2 = Conv1D(filters=64, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_2_1')(input2)
    # x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_2_2')(x2)
    x2 = Dropout(rate=0.2, name='dropout_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_2_3')(x2)
    x2 = GlobalMaxPooling1D(name='gap1d_2_1')(x2)
    
    # Third input branch
    input3 = Input(shape=input_shape3, name='input3')
    x3 = Conv1D(filters=64, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_3_1')(input3)
    # x3 = MaxPooling1D(pool_size=2, name='maxpool1d_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_3_2')(x3)
    x3 = Dropout(rate=0.2, name='dropout_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_3_3')(x3)
    x3 = GlobalMaxPooling1D(name='gap1d_3_1')(x3)
    
    # Concatenate the outputs of the three branches
    merged = concatenate([x1, x2, x3], name='concatenate_1')
    
    # Dense layer
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='sigmoid', name='output')(dense)
    
    model = Model(inputs=[input1, input2, input3], outputs=output)
    return model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = np.dstack((data[:, :, 0], data[:, :, 2]))
        globals()[f"{key}2"] = np.dstack((data[:, :, 2],))
        globals()[f"{key}3"] = np.dstack((data[:, :, 6], data[:, :, 8]))
        # Uncomment and modify the line below if you need the fourth set
        # globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 800, 2)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 800, 1)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 800, 2)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 80, 128)   │     10,368 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 80, 64)    │      2,624 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 80, 64)    │      5,184 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 37, 128)   │    131,200 │ conv1d_1_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 37, 128)   │     65,664 │ conv1d_2_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 37, 128)   │     65,664 │ conv1d_3_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 37, 128)   │          0 │ conv1d_1_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 37, 128)   │          0 │ conv1d_2_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_3_1         │ (None, 37, 128)   │          0 │ conv1d_3_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 36, 256)   │     65,792 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 36, 128)   │     32,896 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 36, 128)   │     32,896 │ dropout_3_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 256)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 128)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 128)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 512)       │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │     32,832 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 16)        │      1,040 │ dense_1[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 1)         │         17 │ dense_2[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 1,338,533 (5.11 MB)
 Trainable params: 446,177 (1.70 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 892,356 (3.40 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f354c1865c0>
Loss Function: binary_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.04770096391439438
Test val_loss: 0.27507737278938293
Train accuracy: 0.9852104783058167
Accuracy Score: 0.9453924914675768
F1 Score: 0.9506172839506173
Classification Report:
               precision    recall  f1-score   support

         0.0       0.93      0.95      0.94       130
         1.0       0.96      0.94      0.95       163

    accuracy                           0.95       293
   macro avg       0.94      0.95      0.94       293
weighted avg       0.95      0.95      0.95       293

Training History:
accuracy: [0.57337886095047, 0.7064846158027649, 0.7519909143447876, 0.7622298002243042, 0.788395881652832, 0.7576791644096375, 0.8225256204605103, 0.8202502727508545, 0.8418657779693604, 0.8680318593978882, 0.8759954571723938, 0.8828213810920715, 0.891922652721405, 0.8816837072372437, 0.9180887341499329, 0.912400484085083, 0.9135380983352661, 0.8896473050117493, 0.9180887341499329, 0.9215016961097717, 0.9317406415939331, 0.9237770438194275, 0.9499431252479553, 0.9408418536186218, 0.9385665655136108, 0.9579067230224609, 0.9522184133529663, 0.9465301632881165, 0.9533560872077942, 0.9601820111274719, 0.9624573588371277, 0.9533560872077942, 0.9635949730873108, 0.9715585708618164, 0.8964732885360718, 0.9488054513931274, 0.9738339185714722, 0.9692832827568054, 0.9817975163459778, 0.9817975163459778, 0.977246880531311, 0.9852104783058167]
loss: [0.6871153712272644, 0.5666782855987549, 0.5223501324653625, 0.5049729943275452, 0.4349703788757324, 0.49871957302093506, 0.4014894366264343, 0.3577767312526703, 0.3201344311237335, 0.2751690447330475, 0.26918143033981323, 0.2796572744846344, 0.2442258894443512, 0.27781638503074646, 0.21145516633987427, 0.21624481678009033, 0.20626333355903625, 0.27374956011772156, 0.19260986149311066, 0.1878025084733963, 0.17588798701763153, 0.17343614995479584, 0.13094423711299896, 0.1390732079744339, 0.14506351947784424, 0.1032058522105217, 0.11266053467988968, 0.14043469727039337, 0.10867604613304138, 0.10285323113203049, 0.1065845787525177, 0.10872260481119156, 0.09116748720407486, 0.07483106106519699, 0.23456747829914093, 0.1297319233417511, 0.07393860071897507, 0.07684125751256943, 0.052041761577129364, 0.04761991649866104, 0.056838613003492355, 0.04770096391439438]
val_accuracy: [0.6962457299232483, 0.7713310718536377, 0.7201365232467651, 0.6860068440437317, 0.7849829196929932, 0.7133105993270874, 0.80887371301651, 0.8464163541793823, 0.8703071475028992, 0.8430033922195435, 0.8805460929870605, 0.8703071475028992, 0.8020477890968323, 0.873720109462738, 0.9044368863105774, 0.8634812235832214, 0.894197940826416, 0.8976109027862549, 0.9044368863105774, 0.914675772190094, 0.8805460929870605, 0.8634812235832214, 0.9180887341499329, 0.873720109462738, 0.8907849788665771, 0.9249146580696106, 0.9283276200294495, 0.9044368863105774, 0.9283276200294495, 0.9283276200294495, 0.9044368863105774, 0.914675772190094, 0.914675772190094, 0.8566552996635437, 0.8122866749763489, 0.9180887341499329, 0.9249146580696106, 0.9249146580696106, 0.935153603553772, 0.914675772190094, 0.9249146580696106, 0.9249146580696106]
val_loss: [0.5968930721282959, 0.5161697268486023, 0.5648500919342041, 0.5957351326942444, 0.4599011540412903, 0.5288406014442444, 0.41518107056617737, 0.38839423656463623, 0.3365158140659332, 0.3800746202468872, 0.31832441687583923, 0.36091992259025574, 0.5044429898262024, 0.3385617434978485, 0.28318527340888977, 0.3425630033016205, 0.2883321940898895, 0.28466692566871643, 0.2697291970252991, 0.24097059667110443, 0.2698034942150116, 0.2769445478916168, 0.25984951853752136, 0.32784828543663025, 0.26872456073760986, 0.233389213681221, 0.22810925543308258, 0.2927337884902954, 0.22963492572307587, 0.20894648134708405, 0.2527589499950409, 0.2900187373161316, 0.24323683977127075, 0.3785671591758728, 0.538811206817627, 0.22697113454341888, 0.2523624002933502, 0.2187952846288681, 0.24157071113586426, 0.2805415093898773, 0.22751294076442719, 0.27507737278938293]

Confusion Matrix:
[[123   7]
 [  9 154]]

################################################################################################ 

