Building Function:
def build_SeparatedEASYmodel(input_shape1, input_shape2, input_shape3):
    # First input branch
    input1 = Input(shape=input_shape1, name='input1')
    x1 = Conv1D(128, kernel_size=40, strides=8, activation='relu', name='conv1d_1_1')(input1)
    x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_1')(x1)
    x1 = Conv1D(128, kernel_size=20, strides=2, activation='relu', name='conv1d_1_2')(x1)
    #x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_2')(x1)
    x1 = Conv1D(256, kernel_size=4, activation='relu', name='conv1d_1_3')(x1)
    x1 = GlobalMaxPooling1D(name='globalmaxpool1d_1_1')(x1)
    #x1 = Dense(128, activation='relu', name='dense_1_1')(x1)
    x1 = Dropout(0.2, name='dropout_1_1')(x1)
    out1 = Dense(64, activation='relu', name='dense_1_2')(x1)

    # Second input branch
    input2 = Input(shape=input_shape2, name='input2')
    x2 = Conv1D(128, kernel_size=2, activation='relu', name='conv1d_2_1')(input2)
    #x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_1')(x2)
    x2 = Conv1D(64, kernel_size=8, strides=2, activation='relu', name='conv1d_2_2')(x2)
    #x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_2')(x2)
    x2 = Conv1D(128, kernel_size=4, activation='relu', name='conv1d_2_3')(x2)
    x2 = Conv1D(64, kernel_size=2, activation='relu', name='conv1d_2_4')(x2)
    x2 = GlobalMaxPooling1D(name='globalmaxpool1d_2_1')(x2)
    x2 = Dropout(0.2, name='dropout_2_1')(x2)
    out2 = Dense(64, activation='relu', name='dense_2_1')(x2)

    # Third input branch
    input3 = Input(shape=input_shape3, name='input3')
    x3 = Conv1D(64, kernel_size=40, strides=10, activation='relu', name='conv1d_3_1')(input3)
    #x3 = MaxPooling1D(pool_size=2, name='maxpool1d_3_1')(x3)
    x3 = Conv1D(64, kernel_size=10, activation='relu', name='conv1d_3_2')(x3)
    # x3 = MaxPooling1D(pool_size=2, name='maxpool1d_3_2')(x3)
    # x3 = Flatten(name='flatten_3_1')(x3)
    x3 = GlobalMaxPooling1D(name = 'globalmaxpool1d_3_1')(x3)
    out3 = Dense(64, activation='relu', name='dense_3_1')(x3)

    # Concatenate the outputs of the branches
    merged = concatenate([out1, out2, out3], name='concatenate_1')
    merged = Dropout(0.25, name='dropout_merged')(merged)
    merged = Dense(64, activation='relu', name='dense_merged_1')(merged)
    output = Dense(1, activation='sigmoid', name='output')(merged)

    # Create the model
    separated_model = Model(inputs=[input1, input2, input3], outputs=output)

    return separated_model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = np.dstack((data[:, :, 0], data[:, :, 2]))
        globals()[f"{key}2"] = np.dstack((data[:, :, 3],))
        globals()[f"{key}3"] = np.dstack((data[:, :, 2], data[:, :, 0]))
        # Uncomment and modify the line below if you need the fourth set
        # globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional_13"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 800, 2)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 800, 1)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 96, 128)   │     10,368 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 799, 128)  │        384 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_1_1       │ (None, 48, 128)   │          0 │ conv1d_1_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 396, 64)   │     65,600 │ conv1d_2_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 15, 128)   │    327,808 │ maxpool1d_1_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 393, 128)  │     32,896 │ conv1d_2_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 800, 2)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 12, 256)   │    131,328 │ conv1d_1_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_4 (Conv1D) │ (None, 392, 64)   │     16,448 │ conv1d_2_3[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 77, 64)    │      5,184 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ globalmaxpool1d_1_1 │ (None, 256)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ globalmaxpool1d_2_1 │ (None, 64)        │          0 │ conv1d_2_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 68, 64)    │     41,024 │ conv1d_3_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 256)       │          0 │ globalmaxpool1d_… │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 64)        │          0 │ globalmaxpool1d_… │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ globalmaxpool1d_3_1 │ (None, 64)        │          0 │ conv1d_3_2[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1_2 (Dense)   │ (None, 64)        │     16,448 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2_1 (Dense)   │ (None, 64)        │      4,160 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_3_1 (Dense)   │ (None, 64)        │      4,160 │ globalmaxpool1d_… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 192)       │          0 │ dense_1_2[0][0],  │
│ (Concatenate)       │                   │            │ dense_2_1[0][0],  │
│                     │                   │            │ dense_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_merged      │ (None, 192)       │          0 │ concatenate_1[0]… │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_merged_1      │ (None, 64)        │     12,352 │ dropout_merged[0… │
│ (Dense)             │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 1)         │         65 │ dense_merged_1[0… │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,004,677 (7.65 MB)
 Trainable params: 668,225 (2.55 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,336,452 (5.10 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7fca8473c3a0>
Loss Function: binary_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.09282996505498886
Test val_loss: 0.2297651320695877
Train accuracy: 0.9658703207969666
Accuracy Score: 0.9453924914675768
F1 Score: 0.9493670886075949
Classification Report:
               precision    recall  f1-score   support

         0.0       0.91      0.98      0.94       130
         1.0       0.98      0.92      0.95       163

    accuracy                           0.95       293
   macro avg       0.94      0.95      0.95       293
weighted avg       0.95      0.95      0.95       293

Training History:
accuracy: [0.5563139915466309, 0.6939704418182373, 0.7679181098937988, 0.7474402785301208, 0.786120593547821, 0.7872582674026489, 0.7827076315879822, 0.7929465174674988, 0.8191125988960266, 0.8111490607261658, 0.8202502727508545, 0.852104663848877, 0.852104663848877, 0.8532423377037048, 0.8703071475028992, 0.8759954571723938, 0.8816837072372437, 0.9044368863105774, 0.9067121744155884, 0.8873720169067383, 0.9135380983352661, 0.914675772190094, 0.9192264080047607, 0.9340159296989441, 0.9362912178039551, 0.9249146580696106, 0.9294652938842773, 0.9362912178039551, 0.9362912178039551, 0.939704179763794, 0.937428891658783, 0.9465301632881165, 0.9499431252479553, 0.9590443968772888, 0.9658703207969666]
loss: [0.697975754737854, 0.5983525514602661, 0.4947913587093353, 0.508399248123169, 0.4651029706001282, 0.4349626302719116, 0.4358008801937103, 0.4102814495563507, 0.38883528113365173, 0.40273037552833557, 0.36981096863746643, 0.34093916416168213, 0.33286023139953613, 0.3115960359573364, 0.2853628993034363, 0.28748223185539246, 0.27579814195632935, 0.2371606081724167, 0.22289134562015533, 0.25899738073349, 0.22399643063545227, 0.2225651890039444, 0.2073553055524826, 0.17700617015361786, 0.16827738285064697, 0.18948718905448914, 0.1859477013349533, 0.16243262588977814, 0.1546577513217926, 0.14394201338291168, 0.16060899198055267, 0.13795442879199982, 0.10641230642795563, 0.10765964537858963, 0.09282996505498886]
val_accuracy: [0.7064846158027649, 0.7849829196929932, 0.788395881652832, 0.7918089032173157, 0.8259385824203491, 0.788395881652832, 0.8054607510566711, 0.8020477890968323, 0.80887371301651, 0.829351544380188, 0.8532423377037048, 0.8430033922195435, 0.8361774682998657, 0.873720109462738, 0.873720109462738, 0.8805460929870605, 0.9010238647460938, 0.9044368863105774, 0.8873720169067383, 0.873720109462738, 0.8907849788665771, 0.9044368863105774, 0.9180887341499329, 0.9044368863105774, 0.9180887341499329, 0.9078498482704163, 0.9078498482704163, 0.9215016961097717, 0.9044368863105774, 0.9010238647460938, 0.9180887341499329, 0.9180887341499329, 0.914675772190094, 0.9180887341499329, 0.9249146580696106]
val_loss: [0.6255348920822144, 0.4751940071582794, 0.4570513665676117, 0.415950745344162, 0.4070279896259308, 0.3776303827762604, 0.38198602199554443, 0.37412017583847046, 0.38758373260498047, 0.33614546060562134, 0.3050220012664795, 0.3491656482219696, 0.31679511070251465, 0.2791734039783478, 0.287192702293396, 0.279693603515625, 0.2544915974140167, 0.23116107285022736, 0.24937480688095093, 0.26653939485549927, 0.22821877896785736, 0.24628782272338867, 0.2118338942527771, 0.22477667033672333, 0.2134810835123062, 0.22467975318431854, 0.21776987612247467, 0.22083373367786407, 0.21672195196151733, 0.2563050091266632, 0.22970950603485107, 0.23173512518405914, 0.22992484271526337, 0.23878401517868042, 0.2297651320695877]

Confusion Matrix:
[[127   3]
 [ 13 150]]

################################################################################################ 

