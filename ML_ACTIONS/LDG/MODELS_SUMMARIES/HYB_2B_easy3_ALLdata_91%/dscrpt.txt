def build_TwoBranchModel(F_input_shape, S_input_shape, num_classes):
    # 1D Data Branch
    input_1D = tf.keras.layers.Input(shape=F_input_shape, name='input_1D')
    conv1_1D = tf.keras.layers.Conv1D(64, kernel_size=40, strides=10, name='conv1_1D')(input_1D)
    conv1_1D = tf.keras.layers.Activation('relu')(conv1_1D)
    pool1_1D = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1_1D)

    conv2_1D = tf.keras.layers.Conv1D(128, kernel_size=8, strides=4, name='conv2_1D')(pool1_1D)
    conv2_1D = tf.keras.layers.Activation('relu')(conv2_1D)
    #pool2_1D = tf.keras.layers.GlobalMaxPooling1D()(conv2_1D)

    conv3_1D = tf.keras.layers.Conv1D(128, kernel_size=4, strides=1, name='conv3_1D')(conv2_1D)
    conv3_1D = tf.keras.layers.Activation('relu')(conv3_1D)
    pool3_1D = tf.keras.layers.GlobalMaxPooling1D()(conv3_1D)

    flatten_1D = tf.keras.layers.Flatten()(pool3_1D)

    # 2D Data Branch (Scaleograms)
    input_2D = tf.keras.layers.Input(shape=S_input_shape, name='input_2D')
    conv1_2D = tf.keras.layers.Conv2D(64, kernel_size=(20, 20), strides=(10,10), padding='same', name='conv1_2D')(input_2D)
    conv1_2D = tf.keras.layers.Activation('relu')(conv1_2D)
    pool1_2D = tf.keras.layers.MaxPooling2D(pool_size=(4, 4))(conv1_2D)

    conv2_2D = tf.keras.layers.Conv2D(128, kernel_size=(10, 10), strides=(5,5), padding='same', name='conv2_2D')(pool1_2D)
    conv2_2D = tf.keras.layers.Activation('relu')(conv2_2D)
    
    conv3_2D = tf.keras.layers.Conv2D(256, kernel_size=(4, 4), strides=(2,2), padding='same', name='conv3_2D')(conv2_2D)
    conv3_2D = tf.keras.layers.Activation('relu')(conv3_2D)
    pool3_2D = tf.keras.layers.GlobalMaxPooling2D()(conv3_2D)

    flatten_2D = tf.keras.layers.Flatten()(pool3_2D)

    # Merge branches
    merged = tf.keras.layers.concatenate([flatten_1D, flatten_2D])

    # Fully Connected Layers
    fc = tf.keras.layers.Dense(128, activation='relu')(merged)
    fc = tf.keras.layers.Dense(64, activation='relu')(fc)
    output = tf.keras.layers.Dense(num_classes, activation='softmax')(fc)

    # Define the Model
    model = tf.keras.Model(inputs=[input_1D, input_2D], outputs=output, name='TwoBranchModel')
    return model

Model: "TwoBranchModel"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_1D            │ (None, 3000, 9)   │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input_2D            │ (None, 3000, 768, │          0 │ -                 │
│ (InputLayer)        │ 1)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1_1D (Conv1D)   │ (None, 297, 64)   │     23,104 │ input_1D[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1_2D (Conv2D)   │ (None, 300, 77,   │     25,664 │ input_2D[0][0]    │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_18       │ (None, 297, 64)   │          0 │ conv1_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_21       │ (None, 300, 77,   │          0 │ conv1_2D[0][0]    │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_4     │ (None, 148, 64)   │          0 │ activation_18[0]… │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_4     │ (None, 75, 19,    │          0 │ activation_21[0]… │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2_1D (Conv1D)   │ (None, 36, 128)   │     65,664 │ max_pooling1d_4[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2_2D (Conv2D)   │ (None, 15, 4,     │    819,328 │ max_pooling2d_4[… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_19       │ (None, 36, 128)   │          0 │ conv2_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_22       │ (None, 15, 4,     │          0 │ conv2_2D[0][0]    │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv3_1D (Conv1D)   │ (None, 33, 128)   │     65,664 │ activation_19[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv3_2D (Conv2D)   │ (None, 8, 2, 256) │    524,544 │ activation_22[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_20       │ (None, 33, 128)   │          0 │ conv3_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_23       │ (None, 8, 2, 256) │          0 │ conv3_2D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 128)       │          0 │ activation_20[0]… │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 256)       │          0 │ activation_23[0]… │
│ (GlobalMaxPooling2… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ flatten_8 (Flatten) │ (None, 128)       │          0 │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ flatten_9 (Flatten) │ (None, 256)       │          0 │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_4       │ (None, 384)       │          0 │ flatten_8[0][0],  │
│ (Concatenate)       │                   │            │ flatten_9[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_12 (Dense)    │ (None, 128)       │     49,280 │ concatenate_4[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_13 (Dense)    │ (None, 64)        │      8,256 │ dense_12[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_14 (Dense)    │ (None, 4)         │        260 │ dense_13[0][0]    │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 4,745,294 (18.10 MB)
 Trainable params: 1,581,764 (6.03 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 3,163,530 (12.07 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f7af8470a90>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.5353121757507324
Test val_loss: 1.8235305547714233
Train accuracy: 0.8449612259864807
Accuracy Score: 0.9069767441860465
F1 Score: 0.9123517786561266
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.94      0.97        17
         1.0       1.00      0.84      0.91        25
         2.0       0.80      0.87      0.83        23
         3.0       0.88      1.00      0.93        21

    accuracy                           0.91        86
   macro avg       0.92      0.91      0.91        86
weighted avg       0.92      0.91      0.91        86

Training History:
accuracy: [0.39922481775283813, 0.5968992114067078, 0.7286821603775024, 0.7248061895370483, 0.8333333134651184, 0.8062015771865845, 0.9031007885932922, 0.8255813717842102, 0.8139534592628479, 0.8992248177528381, 0.9263566136360168, 0.9263566136360168, 0.9573643207550049, 0.9573643207550049, 0.9457364082336426, 0.9457364082336426, 0.9147287011146545, 0.9457364082336426, 0.934108555316925, 0.9573643207550049, 0.9108527302742004, 0.8720930218696594, 0.8488371968269348, 0.9108527302742004, 0.8062015771865845, 0.9186046719551086, 0.930232584476471, 0.9379844665527344, 0.9263566136360168, 0.930232584476471, 0.9573643207550049, 0.9418604373931885, 0.8992248177528381, 0.8410852551460266, 0.8875969052314758, 0.930232584476471, 0.8449612259864807]
loss: [1.3062036037445068, 0.9022424221038818, 0.5978087782859802, 0.5820745229721069, 0.4983174502849579, 0.4053049087524414, 0.27239513397216797, 0.48526862263679504, 0.3875255882740021, 0.25010502338409424, 0.18038924038410187, 0.2029702365398407, 0.12897734344005585, 0.12302421033382416, 0.1310146600008011, 0.1629546582698822, 0.18826168775558472, 0.1404091715812683, 0.1513015180826187, 0.10925716161727905, 0.2284998893737793, 0.36924687027931213, 0.4149111211299896, 0.2641410529613495, 0.47245174646377563, 0.23219913244247437, 0.1902160346508026, 0.17590445280075073, 0.24011456966400146, 0.18483245372772217, 0.10743726789951324, 0.15015414357185364, 0.19454842805862427, 0.4671679437160492, 0.28212064504623413, 0.20723770558834076, 0.5353121757507324]
val_accuracy: [0.2906976640224457, 0.4767441749572754, 0.6627907156944275, 0.7906976938247681, 0.7558139562606812, 0.8488371968269348, 0.6860465407371521, 0.7790697813034058, 0.8372092843055725, 0.9069767594337463, 0.8255813717842102, 0.8604651093482971, 0.8837209343910217, 0.895348846912384, 0.8139534592628479, 0.8604651093482971, 0.8837209343910217, 0.8720930218696594, 0.9186046719551086, 0.895348846912384, 0.895348846912384, 0.8139534592628479, 0.8372092843055725, 0.7790697813034058, 0.8604651093482971, 0.8837209343910217, 0.895348846912384, 0.8488371968269348, 0.9186046719551086, 0.8837209343910217, 0.8604651093482971, 0.8372092843055725, 0.8720930218696594, 0.8604651093482971, 0.8720930218696594, 0.8837209343910217, 0.6511628031730652]
val_loss: [1.6257283687591553, 1.0058046579360962, 0.7875456809997559, 0.5052036046981812, 0.5153529047966003, 0.3947603106498718, 0.6053741574287415, 0.5429863333702087, 0.43736201524734497, 0.37249186635017395, 0.630158007144928, 0.3744540512561798, 0.4265241324901581, 0.3721407651901245, 0.5060118436813354, 0.517036497592926, 0.4046197831630707, 0.3853094279766083, 0.3283862769603729, 0.430099219083786, 0.39194896817207336, 0.5462785959243774, 0.5448349118232727, 0.4757064878940582, 0.3043825626373291, 0.31890371441841125, 0.39032790064811707, 0.4437223970890045, 0.2399156242609024, 0.30029726028442383, 0.33379504084587097, 0.5334901809692383, 0.4443233907222748, 0.38894015550613403, 0.335422545671463, 0.3348321318626404, 1.8235305547714233]

################################################################################################ 

