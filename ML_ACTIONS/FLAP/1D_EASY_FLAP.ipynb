{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/user/thesis_ws/src/ML/UTILITIES')\n",
    "from PreProcessingFunctions import myfilter, num_transient, sliding_sum_window, select_index, add_padding\n",
    "from PreProcessingFunctions import WS\n",
    "from PreProcessingFunctions import rename_and_convert_to_txt\n",
    "\n",
    "from OrganizeReports import compare_and_organize\n",
    "from Performance_plotter import plot_f1_score_threshold, plot_precision_recall_curve, plot_confusion_matrix, plot_roc_curve\n",
    "from ML_models_functions import to_save_model, free_gpu_memory\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import tensorflow\n",
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "if gpus:    \n",
    "    for gpu in gpus:\n",
    "        tensorflow.config.set_logical_device_configuration(\n",
    "            gpu,\n",
    "            [tensorflow.config.LogicalDeviceConfiguration(memory_limit=4*1024)])  # Adjust memory limit as needed\n",
    "\n",
    "\n",
    "from tensorflow.keras.models     import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers     import Input, Conv1D, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers     import Flatten, Dense, MaxPooling1D, MaxPooling2D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers     import LeakyReLU, ReLU, Activation, Dropout, Lambda\n",
    "from tensorflow.keras.layers     import concatenate, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from tensorflow.keras.losses     import binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras.metrics    import AUC, Precision, Recall\n",
    "from tensorflow.keras.callbacks  import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.utils      import plot_model\n",
    "\n",
    "data_folder = '/home/user/thesis_ws/src/ML_ACTIONS/DATA/1D_FLAP_F_ScalNorm'\n",
    "\n",
    "def load_data(data_folder):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    # Get list of all .npz files in the data folder\n",
    "    npz_files = [file for file in os.listdir(data_folder) if file.endswith('.npz')]\n",
    "    \n",
    "    # Load data from each .npz file\n",
    "    for file in npz_files:\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        data = np.load(file_path)\n",
    "        X_data.append(data['X'])  # Assuming X_data is stored under 'X' key in the .npz file\n",
    "        y_data.append(data['y'])  # Assuming y_data is stored under 'y' key in the .npz file\n",
    "        data.close()\n",
    "    \n",
    "    # Convert lists to NumPy arrays\n",
    "    X_data = np.array(X_data)\n",
    "    y_data = np.array(y_data)\n",
    "    \n",
    "    return X_data, y_data\n",
    "\n",
    "# Load the data\n",
    "X_data, y_data = load_data(data_folder)\n",
    "\n",
    "# Check the shape of loaded data\n",
    "print(\"X_data shape:\", X_data.shape)\n",
    "print(\"y_data shape:\", y_data.shape)\n",
    "print(\"X_data.[0] shape: \", X_data[0].shape)\n",
    "\n",
    "TEST_SIZE = 0.4\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_data, y_data, test_size=TEST_SIZE, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"TOTAL DATA: {len(X_data)}  ||  Train = {100*(1-TEST_SIZE)}%  ||  Test = {100*TEST_SIZE}%\")\n",
    "print(\"Dimensions of X_train:\", X_train.shape, \"   ||  Dimensions of y_train:\", y_train.shape)\n",
    "print(\"Dimensions of X_test: \", X_test.shape, \"   ||  Dimensions of y_test: \", y_test.shape)\n",
    "print(\"Dimensions of X_val:  \", X_val.shape, \"   ||  Dimensions of y_val:  \", y_val.shape)\n",
    "\n",
    "WS_B = 1800\n",
    "N_CLASS = 3\n",
    "DISP_LABELS = [\"0\", \"1\", \"2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 CONVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_easyModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=40, strides=10, activation='relu', input_shape=(WS_B, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    #model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(N_CLASS, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model_name = \"1D_easy1Conv\"\n",
    "model = build_easyModel()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#TRAIN THE MODEL\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=22, batch_size=32, validation_data=(X_val, y_val), verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1) \n",
    "\n",
    "f1 = f1_score(y_test, y_pred_labels, average='macro') \n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# Plot Loss Value\n",
    "axs[0].plot(history.history[\"loss\"], label=\"loss (Training)\")\n",
    "axs[0].plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "axs[0].set_title(\"Loss Value\")\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "axs[1].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "axs[1].plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend()\n",
    "plt.suptitle(f\"EasyModel TaT: {TEST_SIZE}, accur: {accuracy:.4f}, F1: {f1:.4f}, TestLoss: {loss:.4f}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Train loss:\", history.history[\"loss\"][-1])\n",
    "print(\"Test val_loss:\", history.history[\"val_loss\"][-1])\n",
    "print(\"Train accuracy:\", history.history[\"accuracy\"][-1])\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_labels))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=DISP_LABELS)\n",
    "disp.plot()  # You can adjust the colormap as needed\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red;\"> PLOT F1 SCORE AND F1 WRT ALL the THRESHOLDS</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 CONVs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_easyModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=256, kernel_size=10, strides=4, activation='relu', input_shape=(WS_B, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=4, activation='relu'))\n",
    "    #model.add(GlobalMaxPooling1D())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(N_CLASS, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_easyModel()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#TRAIN THE MODEL\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=32, batch_size=32, validation_data=(X_val, y_val), verbose=1,callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1) \n",
    "\n",
    "f1 = f1_score(y_test, y_pred_labels, average='macro') \n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# Plot Loss Value\n",
    "axs[0].plot(history.history[\"loss\"], label=\"loss (Training)\")\n",
    "axs[0].plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "axs[0].set_title(\"Loss Value\")\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "axs[1].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "axs[1].plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend()\n",
    "plt.suptitle(f\"EasyModel TaT: {TEST_SIZE}, accur: {accuracy:.4f}, F1: {f1:.4f}, TestLoss: {loss:.4f}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Train loss:\", history.history[\"loss\"][-1])\n",
    "print(\"Test val_loss:\", history.history[\"val_loss\"][-1])\n",
    "print(\"Train accuracy:\", history.history[\"accuracy\"][-1])\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_labels))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=DISP_LABELS)\n",
    "disp.plot()  # You can adjust the colormap as needed\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"1D_LEVER_2Cnv_96\"\n",
    "# to_save_model(model, history, loss, accuracy, f1, model_name, y_test, y_pred_labels, build_easyModel)\n",
    "# #model.save(f\"{model_name}.h5\")\n",
    "# from tensorflow.keras.models import save_model\n",
    "# save_dir = \"saved_models/\"\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "# model_path = os.path.join(save_dir, f\"{model_name}.keras\")\n",
    "# save_model(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 CONVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_easyModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, kernel_size=40, strides=20, activation='relu', input_shape=(WS_B, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(128, kernel_size=8, strides=4, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(128, kernel_size=2, activation='relu'))\n",
    "    #model.add(GlobalMaxPooling1D())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(N_CLASS, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "model = build_easyModel()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#TRAIN THE MODEL\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=32, batch_size=32, validation_data=(X_val, y_val), verbose=1,callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1) \n",
    "\n",
    "f1 = f1_score(y_test, y_pred_labels, average='macro') \n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# Plot Loss Value\n",
    "axs[0].plot(history.history[\"loss\"], label=\"loss (Training)\")\n",
    "axs[0].plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "axs[0].set_title(\"Loss Value\")\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "axs[1].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "axs[1].plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend()\n",
    "plt.suptitle(f\"EasyModel TaT: {TEST_SIZE}, accur: {accuracy:.4f}, F1: {f1:.4f}, TestLoss: {loss:.4f}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Train loss:\", history.history[\"loss\"][-1])\n",
    "print(\"Test val_loss:\", history.history[\"val_loss\"][-1])\n",
    "print(\"Train accuracy:\", history.history[\"accuracy\"][-1])\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_labels))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=DISP_LABELS)\n",
    "disp.plot()  # You can adjust the colormap as needed\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 CONVs or Still \"COMPLEX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_easyModel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=256, kernel_size=20, strides=4, activation='relu', input_shape=(WS_B, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=256, kernel_size=16, strides=4, activation='relu')) #LeakyReLU(alpha=0.001)\n",
    "    model.add(Dropout(rate=0.1))\n",
    "    \n",
    "    model.add(Conv1D(filters=128, kernel_size=8, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=4, activation='relu'))\n",
    "    #model.add(GlobalMaxPooling1D())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(N_CLASS, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = build_easyModel()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#TRAIN THE MODEL\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_val, y_val), verbose=1,callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1) \n",
    "\n",
    "f1 = f1_score(y_test, y_pred_labels, average='macro') \n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# Plot Loss Value\n",
    "axs[0].plot(history.history[\"loss\"], label=\"loss (Training)\")\n",
    "axs[0].plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "axs[0].set_title(\"Loss Value\")\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "axs[1].plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "axs[1].plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend()\n",
    "plt.suptitle(f\"EasyModel TaT: {TEST_SIZE}, accur: {accuracy:.4f}, F1: {f1:.4f}, TestLoss: {loss:.4f}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Train loss:\", history.history[\"loss\"][-1])\n",
    "print(\"Test val_loss:\", history.history[\"val_loss\"][-1])\n",
    "print(\"Train accuracy:\", history.history[\"accuracy\"][-1])\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_labels))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=DISP_LABELS)\n",
    "disp.plot()  # You can adjust the colormap as needed\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 CONVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
