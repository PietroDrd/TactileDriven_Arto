def build_TwoBranchModel(F_input_shape, S_input_shape, num_classes):
    # 1D Data Branch
    input_1D = tf.keras.layers.Input(shape=F_input_shape, name='input_1D')
    conv1_1D = tf.keras.layers.Conv1D(64, kernel_size=40, strides=10, name='conv1_1D')(input_1D)
    conv1_1D = tf.keras.layers.Activation('relu')(conv1_1D)
    pool1_1D = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1_1D)

    conv2_1D = tf.keras.layers.Conv1D(128, kernel_size=8, strides=4, name='conv2_1D')(pool1_1D)
    conv2_1D = tf.keras.layers.Activation('relu')(conv2_1D)
    #pool2_1D = tf.keras.layers.GlobalMaxPooling1D()(conv2_1D)

    conv3_1D = tf.keras.layers.Conv1D(128, kernel_size=4, strides=1, name='conv3_1D')(conv2_1D)
    conv3_1D = tf.keras.layers.Activation('relu')(conv3_1D)
    pool3_1D = tf.keras.layers.GlobalMaxPooling1D()(conv3_1D)

    flatten_1D = tf.keras.layers.Flatten()(pool3_1D)

    # 2D Data Branch (Scaleograms)
    input_2D = tf.keras.layers.Input(shape=S_input_shape, name='input_2D')
    conv1_2D = tf.keras.layers.Conv2D(64, kernel_size=(20, 20), strides=(10,10), padding='same', name='conv1_2D')(input_2D)
    conv1_2D = tf.keras.layers.Activation('relu')(conv1_2D)
    pool1_2D = tf.keras.layers.MaxPooling2D(pool_size=(4, 4))(conv1_2D)

    conv2_2D = tf.keras.layers.Conv2D(128, kernel_size=(10, 10), strides=(5,5), padding='same', name='conv2_2D')(pool1_2D)
    conv2_2D = tf.keras.layers.Activation('relu')(conv2_2D)
    
    conv3_2D = tf.keras.layers.Conv2D(256, kernel_size=(4, 4), strides=(2,2), padding='same', name='conv3_2D')(conv2_2D)
    conv3_2D = tf.keras.layers.Activation('relu')(conv3_2D)
    pool3_2D = tf.keras.layers.GlobalMaxPooling2D()(conv3_2D)

    flatten_2D = tf.keras.layers.Flatten()(pool3_2D)

    # Merge branches
    merged = tf.keras.layers.concatenate([flatten_1D, flatten_2D])

    # Fully Connected Layers
    fc = tf.keras.layers.Dense(128, activation='relu')(merged)
    fc = tf.keras.layers.Dense(64, activation='relu')(fc)
    output = tf.keras.layers.Dense(num_classes, activation='softmax')(fc)

    # Define the Model
    model = tf.keras.Model(inputs=[input_1D, input_2D], outputs=output, name='TwoBranchModel')
    return model

Model: "TwoBranchModel"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_1D            │ (None, 1800, 9)   │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input_2D            │ (None, 1800, 768, │          0 │ -                 │
│ (InputLayer)        │ 1)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1_1D (Conv1D)   │ (None, 177, 64)   │     23,104 │ input_1D[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1_2D (Conv2D)   │ (None, 180, 77,   │     25,664 │ input_2D[0][0]    │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation          │ (None, 177, 64)   │          0 │ conv1_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_3        │ (None, 180, 77,   │          0 │ conv1_2D[0][0]    │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d       │ (None, 88, 64)    │          0 │ activation[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d       │ (None, 45, 19,    │          0 │ activation_3[0][… │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2_1D (Conv1D)   │ (None, 21, 128)   │     65,664 │ max_pooling1d[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2_2D (Conv2D)   │ (None, 9, 4, 128) │    819,328 │ max_pooling2d[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_1        │ (None, 21, 128)   │          0 │ conv2_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_4        │ (None, 9, 4, 128) │          0 │ conv2_2D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv3_1D (Conv1D)   │ (None, 18, 128)   │     65,664 │ activation_1[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv3_2D (Conv2D)   │ (None, 5, 2, 256) │    524,544 │ activation_4[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_2        │ (None, 18, 128)   │          0 │ conv3_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_5        │ (None, 5, 2, 256) │          0 │ conv3_2D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 128)       │          0 │ activation_2[0][… │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 256)       │          0 │ activation_5[0][… │
│ (GlobalMaxPooling2… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ flatten (Flatten)   │ (None, 128)       │          0 │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ flatten_1 (Flatten) │ (None, 256)       │          0 │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate         │ (None, 384)       │          0 │ flatten[0][0],    │
│ (Concatenate)       │                   │            │ flatten_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 128)       │     49,280 │ concatenate[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │      8,256 │ dense[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 4)         │        260 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 4,745,294 (18.10 MB)
 Trainable params: 1,581,764 (6.03 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 3,163,530 (12.07 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7fe5ae6a7850>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.19779111444950104
Test val_loss: 0.2763894200325012
Train accuracy: 0.9283154010772705
Accuracy Score: 0.9354838709677419
F1 Score: 0.9284717607973422
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00        29
         1.0       1.00      0.95      0.98        22
         2.0       0.79      1.00      0.88        22
         3.0       1.00      0.75      0.86        20

    accuracy                           0.94        93
   macro avg       0.95      0.93      0.93        93
weighted avg       0.95      0.94      0.94        93

Training History:
accuracy: [0.38351255655288696, 0.6702508926391602, 0.7777777910232544, 0.7849462628364563, 0.8100358247756958, 0.7849462628364563, 0.8602150678634644, 0.8745519518852234, 0.8351254463195801, 0.8673835396766663, 0.8709677457809448, 0.8673835396766663, 0.8602150678634644, 0.9032257795333862, 0.8960573673248291, 0.939068078994751, 0.9139785170555115, 0.9211469292640686, 0.9247311949729919, 0.9426523447036743, 0.939068078994751, 0.8996415734291077, 0.9283154010772705, 0.9283154010772705]
loss: [1.406794548034668, 0.8532158136367798, 0.5884363055229187, 0.5932108163833618, 0.46362024545669556, 0.44996821880340576, 0.3826755881309509, 0.3221512734889984, 0.33211541175842285, 0.3028453588485718, 0.3235991299152374, 0.37535759806632996, 0.36756500601768494, 0.2442592978477478, 0.241048663854599, 0.17033208906650543, 0.19886189699172974, 0.19686682522296906, 0.1593409925699234, 0.1771136075258255, 0.15022709965705872, 0.23420357704162598, 0.1956454962491989, 0.19779111444950104]
val_accuracy: [0.6236559152603149, 0.7526881694793701, 0.8709677457809448, 0.7634408473968506, 0.8817204236984253, 0.9032257795333862, 0.8709677457809448, 0.9032257795333862, 0.9247311949729919, 0.9139785170555115, 0.8709677457809448, 0.7419354915618896, 0.8602150678634644, 0.8494623899459839, 0.8817204236984253, 0.9139785170555115, 0.8709677457809448, 0.8817204236984253, 0.8709677457809448, 0.8709677457809448, 0.8924731016159058, 0.9032257795333862, 0.8602150678634644, 0.9032257795333862]
val_loss: [1.0456228256225586, 0.5209327340126038, 0.41485390067100525, 0.5092138648033142, 0.2986394166946411, 0.2841370105743408, 0.3258521854877472, 0.2570202350616455, 0.24577932059764862, 0.2262997031211853, 0.3611765205860138, 0.599956214427948, 0.3789522051811218, 0.4182572364807129, 0.3013124465942383, 0.22089871764183044, 0.30521541833877563, 0.2615867257118225, 0.3773825764656067, 0.3634801208972931, 0.34177038073539734, 0.24229560792446136, 0.40597373247146606, 0.2763894200325012]

################################################################################################ 

