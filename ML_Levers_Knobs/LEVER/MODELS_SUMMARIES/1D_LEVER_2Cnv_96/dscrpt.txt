def build_easyModel():
    model = Sequential()
    model.add(Conv1D(filters=256, kernel_size=10, strides=2, activation='relu', input_shape=(WS_B, 1)))
    #model.add(MaxPooling1D(pool_size=2))
    model.add(Conv1D(filters=128, kernel_size=4, activation='relu'))
    model.add(GlobalMaxPooling1D())
    # model.add(MaxPooling1D(pool_size=2))
    # model.add(Flatten())
    model.add(Dense(64, activation='relu'))
    model.add(Dense(3, activation='softmax'))
    return model

Model: "sequential_8"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ conv1d_18 (Conv1D)              │ (None, 996, 256)       │         2,816 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv1d_19 (Conv1D)              │ (None, 993, 128)       │       131,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_max_pooling1d_7          │ (None, 128)            │             0 │
│ (GlobalMaxPooling1D)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_16 (Dense)                │ (None, 64)             │         8,256 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_17 (Dense)                │ (None, 3)              │           195 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 427,403 (1.63 MB)
 Trainable params: 142,467 (556.51 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 284,936 (1.09 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x744dd8194f70>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.2862898111343384
Test val_loss: 0.19683712720870972
Train accuracy: 0.896276593208313
Accuracy Score: 0.9603174603174603
F1 Score: 0.9361679108514552
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00        67
         1.0       1.00      0.88      0.94        42
         2.0       0.77      1.00      0.87        17

    accuracy                           0.96       126
   macro avg       0.92      0.96      0.94       126
weighted avg       0.97      0.96      0.96       126

Training History:
accuracy: [0.396276593208313, 0.539893627166748, 0.6063829660415649, 0.6941489577293396, 0.667553186416626, 0.6941489577293396, 0.6968085169792175, 0.728723406791687, 0.7606382966041565, 0.7686170339584351, 0.7872340679168701, 0.792553186416626, 0.7952127456665039, 0.7792553305625916, 0.8164893388748169, 0.8218085169792175, 0.8617021441459656, 0.8430851101875305, 0.8457446694374084, 0.8723404407501221, 0.875, 0.896276593208313, 0.875, 0.9042553305625916, 0.8882978558540344, 0.8696808218955994, 0.8484042286872864, 0.8803191781044006, 0.896276593208313]
loss: [1.110429048538208, 1.0133060216903687, 0.9706338047981262, 0.922216534614563, 0.8340190052986145, 0.7367040514945984, 0.6754251718521118, 0.6198818683624268, 0.5879830121994019, 0.5259463787078857, 0.5063570737838745, 0.4653313457965851, 0.4760693907737732, 0.47429218888282776, 0.4322246313095093, 0.41429784893989563, 0.40175268054008484, 0.37509533762931824, 0.39416608214378357, 0.35377517342567444, 0.33493611216545105, 0.316251665353775, 0.3119982182979584, 0.30080458521842957, 0.2853013575077057, 0.3152908682823181, 0.38577884435653687, 0.37591251730918884, 0.2862898111343384]
val_accuracy: [0.6111111044883728, 0.6111111044883728, 0.6984127163887024, 0.682539701461792, 0.6984127163887024, 0.7063491940498352, 0.7539682388305664, 0.817460298538208, 0.8650793433189392, 0.8095238208770752, 0.8492063283920288, 0.920634925365448, 0.8095238208770752, 0.8650793433189392, 0.8730158805847168, 0.9523809552192688, 0.976190447807312, 0.8492063283920288, 0.9285714030265808, 0.9444444179534912, 0.89682537317276, 0.8809523582458496, 0.9444444179534912, 0.9682539701461792, 0.9682539701461792, 0.9365079402923584, 0.9523809552192688, 0.9126983880996704, 0.920634925365448]
val_loss: [1.0663671493530273, 1.044219970703125, 0.9591642022132874, 0.840004026889801, 0.7968223094940186, 0.6752822995185852, 0.5968917012214661, 0.43765389919281006, 0.4324587285518646, 0.40915337204933167, 0.36515727639198303, 0.3213738203048706, 0.4333961606025696, 0.32679495215415955, 0.2891908884048462, 0.28159040212631226, 0.25250327587127686, 0.30624669790267944, 0.2670299708843231, 0.23529595136642456, 0.2580176293849945, 0.27252018451690674, 0.2132517546415329, 0.18674848973751068, 0.16586358845233917, 0.21863946318626404, 0.21087706089019775, 0.2025458663702011, 0.19683712720870972]

################################################################################################ 

