def build_branched_model1(input_shape1, input_shape2, input_shape3):
    # First input branch
    input1 = Input(shape=input_shape1, name='input1')
    x1 = Conv1D(filters=128, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_1_1')(input1)
    # x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_1')(x1)
    x1 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_1_2')(x1)
    x1 = Dropout(rate=0.2, name='dropout_1_1')(x1)
    x1 = Conv1D(filters=256, kernel_size=2, strides=1, activation='relu', name='conv1d_1_3')(x1)
    x1 = GlobalMaxPooling1D(name='gap1d_1_1')(x1)
    
    # Second input branch
    input2 = Input(shape=input_shape2, name='input2')
    x2 = Conv1D(filters=64, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_2_1')(input2)
    # x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_2_2')(x2)
    x2 = Dropout(rate=0.2, name='dropout_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_2_3')(x2)
    x2 = GlobalMaxPooling1D(name='gap1d_2_1')(x2)
    
    # Third input branch
    input3 = Input(shape=input_shape3, name='input3')
    x3 = Conv1D(filters=64, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_3_1')(input3)
    # x3 = MaxPooling1D(pool_size=2, name='maxpool1d_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_3_2')(x3)
    x3 = Dropout(rate=0.2, name='dropout_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_3_3')(x3)
    x3 = GlobalMaxPooling1D(name='gap1d_3_1')(x3)
    
    # Concatenate the outputs of the three branches
    merged = concatenate([x1, x2, x3], name='concatenate_1')
    
    # Dense layer
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=[input1, input2, input3], outputs=output)
    return model

Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 2000, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 2000, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 200, 128)  │     10,368 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 200, 64)   │      2,624 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 200, 64)   │      2,624 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 97, 128)   │    131,200 │ conv1d_1_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 97, 128)   │     65,664 │ conv1d_2_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 97, 128)   │     65,664 │ conv1d_3_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 97, 128)   │          0 │ conv1d_1_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 97, 128)   │          0 │ conv1d_2_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_3_1         │ (None, 97, 128)   │          0 │ conv1d_3_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 96, 256)   │     65,792 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 96, 128)   │     32,896 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 96, 128)   │     32,896 │ dropout_3_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 256)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 128)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 128)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 512)       │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │     32,832 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 16)        │      1,040 │ dense_1[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 3)         │         51 │ dense_2[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 1,330,955 (5.08 MB)
 Trainable params: 443,651 (1.69 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 887,304 (3.38 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f56217cec20>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.14312627911567688
Test val_loss: 0.17921549081802368
Train accuracy: 0.9481327533721924
Accuracy Score: 0.9565217391304348
F1 Score: 0.9537688388076746
Classification Report:
               precision    recall  f1-score   support

         0.0       0.97      0.96      0.97        75
         1.0       0.93      0.93      0.93        42
         2.0       0.96      0.98      0.97        44

    accuracy                           0.96       161
   macro avg       0.95      0.96      0.95       161
weighted avg       0.96      0.96      0.96       161

Training History:
accuracy: [0.42323651909828186, 0.4356846511363983, 0.4522821605205536, 0.46680498123168945, 0.4771784245967865, 0.5, 0.5497925281524658, 0.6307054162025452, 0.6514523029327393, 0.7074688673019409, 0.7074688673019409, 0.7593361139297485, 0.7800830006599426, 0.7344398498535156, 0.7946057915687561, 0.8236514329910278, 0.7966805100440979, 0.7925311326980591, 0.8464730381965637, 0.8506224155426025, 0.8423236608505249, 0.865145206451416, 0.7883817553520203, 0.819502055644989, 0.8319501876831055, 0.8858920931816101, 0.8485476970672607, 0.865145206451416, 0.8568464517593384, 0.8713693022727966, 0.8609958291053772, 0.8941908478736877, 0.8921161890029907, 0.9024896025657654, 0.910788357257843, 0.7178423404693604, 0.8319501876831055, 0.865145206451416, 0.8568464517593384, 0.8734439611434937, 0.8547717928886414, 0.8734439611434937, 0.8775933384895325, 0.9004149436950684, 0.9024896025657654, 0.9170124530792236, 0.9045643210411072, 0.9024896025657654, 0.8360995650291443, 0.8941908478736877, 0.9336099624633789, 0.9211618304252625, 0.9024896025657654, 0.8402489423751831, 0.9045643210411072, 0.9170124530792236, 0.9336099624633789, 0.9356846213340759, 0.9460580945014954, 0.9315352439880371, 0.9128630757331848, 0.9460580945014954, 0.9315352439880371, 0.8796680569648743, 0.9377593398094177, 0.908713698387146, 0.9377593398094177, 0.9066389799118042, 0.9336099624633789, 0.9502074718475342, 0.9626556038856506, 0.9688796401023865, 0.9377593398094177, 0.9626556038856506, 0.9605808854103088, 0.9626556038856506, 0.9751037359237671, 0.9709543585777283, 0.9730290174484253, 0.9688796401023865, 0.9771783947944641, 0.9730290174484253, 0.9688796401023865, 0.9834024906158447, 0.9668049812316895, 0.9439833760261536, 0.9709543585777283, 0.9605808854103088, 0.9647302627563477, 0.9481327533721924]
loss: [1.0418391227722168, 0.9666207432746887, 0.9953834414482117, 0.9544918537139893, 0.9361973404884338, 0.8707119226455688, 0.8162105083465576, 0.767552375793457, 0.7074617743492126, 0.6490228176116943, 0.6359284520149231, 0.517004132270813, 0.4851961135864258, 0.5510892271995544, 0.46714141964912415, 0.4449332654476166, 0.46023470163345337, 0.45907723903656006, 0.39051100611686707, 0.3957947790622711, 0.3932183086872101, 0.3576539158821106, 0.5279355645179749, 0.42888790369033813, 0.38517528772354126, 0.3367641568183899, 0.3456646203994751, 0.32520875334739685, 0.3428988754749298, 0.2948349416255951, 0.33362624049186707, 0.28294506669044495, 0.2837100028991699, 0.24667613208293915, 0.24002046883106232, 0.6276907324790955, 0.41387739777565, 0.3434116840362549, 0.36954838037490845, 0.3113223910331726, 0.31751763820648193, 0.3112829923629761, 0.30034738779067993, 0.24074244499206543, 0.25700950622558594, 0.2561676502227783, 0.24113729596138, 0.24515129625797272, 0.3787267208099365, 0.2530434727668762, 0.2044333815574646, 0.21262899041175842, 0.24345318973064423, 0.38685956597328186, 0.26729217171669006, 0.2204003781080246, 0.2027645707130432, 0.17931847274303436, 0.16884984076023102, 0.15550918877124786, 0.2206258922815323, 0.1668683886528015, 0.15582968294620514, 0.2865162193775177, 0.1916394978761673, 0.21426691114902496, 0.17054566740989685, 0.2199147343635559, 0.17527657747268677, 0.1391051858663559, 0.11506308615207672, 0.10518720000982285, 0.16600604355335236, 0.1305982768535614, 0.13991908729076385, 0.1275991052389145, 0.08812348544597626, 0.0919918492436409, 0.08452288806438446, 0.09434416145086288, 0.07681207358837128, 0.07459819316864014, 0.08849537372589111, 0.06074213236570358, 0.07750634849071503, 0.14053310453891754, 0.08133777230978012, 0.085946224629879, 0.10887286812067032, 0.14312627911567688]
val_accuracy: [0.5403726696968079, 0.43478259444236755, 0.44720497727394104, 0.43478259444236755, 0.5093167424201965, 0.5341615080833435, 0.6521739363670349, 0.6459627151489258, 0.7080745100975037, 0.6335403919219971, 0.7763975262641907, 0.8074533939361572, 0.7453415989875793, 0.7453415989875793, 0.8260869383811951, 0.8136646151542664, 0.7267080545425415, 0.8012422323226929, 0.8136646151542664, 0.8322981595993042, 0.8571428656578064, 0.6832298040390015, 0.7950310707092285, 0.8260869383811951, 0.850931704044342, 0.8136646151542664, 0.8074533939361572, 0.7950310707092285, 0.8136646151542664, 0.8260869383811951, 0.8757764101028442, 0.8757764101028442, 0.8447204828262329, 0.8819875717163086, 0.6211180090904236, 0.8012422323226929, 0.8571428656578064, 0.8819875717163086, 0.8447204828262329, 0.8074533939361572, 0.850931704044342, 0.8198757767677307, 0.8819875717163086, 0.8447204828262329, 0.8944099545478821, 0.8322981595993042, 0.8757764101028442, 0.8322981595993042, 0.8757764101028442, 0.8819875717163086, 0.9130434989929199, 0.8819875717163086, 0.9068322777748108, 0.888198733329773, 0.9068322777748108, 0.9130434989929199, 0.8944099545478821, 0.9130434989929199, 0.9130434989929199, 0.782608687877655, 0.8633540272712708, 0.9130434989929199, 0.850931704044342, 0.8819875717163086, 0.9316770434379578, 0.9316770434379578, 0.8757764101028442, 0.8944099545478821, 0.9254658222198486, 0.9503105878829956, 0.9378882050514221, 0.9130434989929199, 0.9316770434379578, 0.9316770434379578, 0.9440993666648865, 0.9316770434379578, 0.9378882050514221, 0.9378882050514221, 0.9378882050514221, 0.9627329111099243, 0.9503105878829956, 0.9689440727233887, 0.9503105878829956, 0.9627329111099243, 0.9440993666648865, 0.9378882050514221, 0.9503105878829956, 0.9192546606063843, 0.8322981595993042, 0.95652174949646]
val_loss: [0.9512994289398193, 0.960640013217926, 0.9443787932395935, 0.9369341731071472, 0.8492687344551086, 0.839120626449585, 0.67181396484375, 0.6894204616546631, 0.6166120171546936, 0.5735686421394348, 0.5351870656013489, 0.466495156288147, 0.5440024137496948, 0.47096478939056396, 0.43226292729377747, 0.4214850962162018, 0.5120725631713867, 0.44432276487350464, 0.3961516320705414, 0.4040261507034302, 0.37843871116638184, 0.6741958260536194, 0.43058449029922485, 0.38218873739242554, 0.38488638401031494, 0.37850093841552734, 0.38667404651641846, 0.37109044194221497, 0.3697572946548462, 0.3595961332321167, 0.33615243434906006, 0.3010536730289459, 0.3457837402820587, 0.3005962669849396, 0.7700849175453186, 0.4021596908569336, 0.35586175322532654, 0.35124748945236206, 0.35052669048309326, 0.39262670278549194, 0.34638214111328125, 0.37718772888183594, 0.3212139904499054, 0.35996192693710327, 0.29828622937202454, 0.38279029726982117, 0.3009078800678253, 0.3912947177886963, 0.3164985775947571, 0.3165016770362854, 0.27408042550086975, 0.3349743187427521, 0.2827755808830261, 0.358417809009552, 0.30816957354545593, 0.3072739243507385, 0.2802712917327881, 0.3106044828891754, 0.2632078528404236, 0.5040240287780762, 0.33981385827064514, 0.27432912588119507, 0.36468198895454407, 0.34234797954559326, 0.2536042630672455, 0.2649945318698883, 0.33334678411483765, 0.308862566947937, 0.24576416611671448, 0.21090252697467804, 0.21498532593250275, 0.24756650626659393, 0.26437893509864807, 0.22369474172592163, 0.21287228167057037, 0.22270287573337555, 0.18425427377223969, 0.19883523881435394, 0.19559039175510406, 0.16875886917114258, 0.20459599792957306, 0.16641740500926971, 0.1729535013437271, 0.1696113795042038, 0.2114505171775818, 0.19070374965667725, 0.19414430856704712, 0.2951202392578125, 0.37248554825782776, 0.17921549081802368]

Confusion Matrix:
[[72  2  1]
 [ 2 39  1]
 [ 0  1 43]]

################################################################################################ 

