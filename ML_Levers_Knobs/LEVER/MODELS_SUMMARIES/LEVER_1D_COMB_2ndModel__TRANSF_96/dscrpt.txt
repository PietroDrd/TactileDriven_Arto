def build_branched_model1(input_shape1, input_shape2, input_shape3):
    # First input branch
    input1 = Input(shape=input_shape1, name='input1')
    x1 = Conv1D(filters=128, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_1_1')(input1)
    # x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_1')(x1)
    x1 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_1_2')(x1)
    x1 = Dropout(rate=0.2, name='dropout_1_1')(x1)
    x1 = Conv1D(filters=256, kernel_size=2, strides=1, activation='relu', name='conv1d_1_3')(x1)
    x1 = GlobalMaxPooling1D(name='gap1d_1_1')(x1)
    
    # Second input branch
    input2 = Input(shape=input_shape2, name='input2')
    x2 = Conv1D(filters=64, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_2_1')(input2)
    # x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_2_2')(x2)
    x2 = Dropout(rate=0.2, name='dropout_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_2_3')(x2)
    x2 = GlobalMaxPooling1D(name='gap1d_2_1')(x2)
    
    # Third input branch
    input3 = Input(shape=input_shape3, name='input3')
    x3 = Conv1D(filters=64, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_3_1')(input3)
    # x3 = MaxPooling1D(pool_size=2, name='maxpool1d_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_3_2')(x3)
    x3 = Dropout(rate=0.2, name='dropout_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_3_3')(x3)
    x3 = GlobalMaxPooling1D(name='gap1d_3_1')(x3)
    
    # Concatenate the outputs of the three branches
    merged = concatenate([x1, x2, x3], name='concatenate_1')
    
    # Dense layer
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=[input1, input2, input3], outputs=output)
    return model

Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 2000, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 200, 128)  │     10,368 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 200, 64)   │      5,184 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 200, 64)   │      2,624 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_1_1       │ (None, 100, 128)  │          0 │ conv1d_1_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_2_1       │ (None, 100, 64)   │          0 │ conv1d_2_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_3_1       │ (None, 100, 64)   │          0 │ conv1d_3_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 47, 128)   │    131,200 │ maxpool1d_1_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 47, 128)   │     65,664 │ maxpool1d_2_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 47, 128)   │     65,664 │ maxpool1d_3_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 47, 128)   │          0 │ conv1d_1_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 47, 128)   │          0 │ conv1d_2_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_3_1         │ (None, 47, 128)   │          0 │ conv1d_3_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 46, 256)   │     65,792 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 46, 128)   │     32,896 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 46, 128)   │     32,896 │ dropout_3_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 256)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 128)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 128)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 512)       │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 128)       │     65,664 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 16)        │      2,064 │ dense_1[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 3)         │         51 │ dense_2[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 1,440,203 (5.49 MB)
 Trainable params: 480,067 (1.83 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 960,136 (3.66 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f0fe4102c80>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.08710398524999619
Test val_loss: 0.11082330346107483
Train accuracy: 0.9688796401023865
Accuracy Score: 0.9565217391304348
F1 Score: 0.9558351454903179
Classification Report:
               precision    recall  f1-score   support

         0.0       0.97      0.95      0.96        75
         1.0       0.89      0.95      0.92        42
         2.0       1.00      0.98      0.99        44

    accuracy                           0.96       161
   macro avg       0.95      0.96      0.96       161
weighted avg       0.96      0.96      0.96       161

Training History:
accuracy: [0.3464730381965637, 0.6016597747802734, 0.5601660013198853, 0.6867219805717468, 0.7219917178153992, 0.7116182446479797, 0.7240663766860962, 0.7365145087242126, 0.7323651313781738, 0.6680498123168945, 0.7925311326980591, 0.8526970744132996, 0.8755186796188354, 0.8775933384895325, 0.9128630757331848, 0.817427396774292, 0.908713698387146, 0.9253112077713013, 0.8257261514663696, 0.9128630757331848, 0.771784245967865, 0.910788357257843, 0.8962655663490295, 0.9294605851173401, 0.9170124530792236, 0.8879668116569519, 0.9336099624633789, 0.9585062265396118, 0.954356849193573, 0.9481327533721924, 0.9522821307182312, 0.9709543585777283, 0.9668049812316895, 0.9336099624633789, 0.9688796401023865, 0.9751037359237671, 0.9751037359237671, 0.9709543585777283, 0.9730290174484253, 0.9709543585777283, 0.9585062265396118, 0.9585062265396118, 0.9751037359237671, 0.9709543585777283, 0.9792531132698059, 0.9771783947944641, 0.9771783947944641, 0.9834024906158447, 0.9771783947944641, 0.9688796401023865, 0.9751037359237671, 0.9751037359237671, 0.9751037359237671, 0.9751037359237671, 0.9273858666419983, 0.954356849193573, 0.9792531132698059, 0.9688796401023865]
loss: [1.0810579061508179, 0.8900617957115173, 0.8909212350845337, 0.6923688054084778, 0.6568396687507629, 0.6341683864593506, 0.6287659406661987, 0.559950590133667, 0.5475307703018188, 0.6771342754364014, 0.4790637195110321, 0.4040043354034424, 0.3624982535839081, 0.35197606682777405, 0.2867412269115448, 0.4228699803352356, 0.2825617492198944, 0.24419556558132172, 0.5009662508964539, 0.2870092988014221, 0.5909604430198669, 0.3121512830257416, 0.27542728185653687, 0.24801167845726013, 0.24463196098804474, 0.27522262930870056, 0.21325255930423737, 0.16568852961063385, 0.1383775919675827, 0.14513270556926727, 0.13585910201072693, 0.1118544414639473, 0.10758452862501144, 0.17106878757476807, 0.11111333221197128, 0.07832295447587967, 0.07966040074825287, 0.0795808658003807, 0.07773604989051819, 0.06821612268686295, 0.1363314837217331, 0.14148005843162537, 0.08794208616018295, 0.08061712980270386, 0.06812828779220581, 0.0869881734251976, 0.07271603494882584, 0.05534213036298752, 0.0761604756116867, 0.08351989835500717, 0.08516307920217514, 0.05743757635354996, 0.060972291976213455, 0.06517383456230164, 0.17861680686473846, 0.13985304534435272, 0.08483167737722397, 0.08710398524999619]
val_accuracy: [0.5031055808067322, 0.6086956262588501, 0.6583850979804993, 0.6770186424255371, 0.6894409656524658, 0.7329192757606506, 0.7329192757606506, 0.6894409656524658, 0.7204968929290771, 0.7453415989875793, 0.8260869383811951, 0.8757764101028442, 0.8695651888847351, 0.888198733329773, 0.8944099545478821, 0.8757764101028442, 0.9192546606063843, 0.7639751434326172, 0.9378882050514221, 0.8757764101028442, 0.9130434989929199, 0.9254658222198486, 0.95652174949646, 0.8819875717163086, 0.9006211161613464, 0.9254658222198486, 0.95652174949646, 0.9378882050514221, 0.95652174949646, 0.9068322777748108, 0.9627329111099243, 0.9503105878829956, 0.9627329111099243, 0.9627329111099243, 0.95652174949646, 0.9813664555549622, 0.9627329111099243, 0.9751552939414978, 0.9751552939414978, 0.9440993666648865, 0.9627329111099243, 0.9689440727233887, 0.9689440727233887, 0.9751552939414978, 0.9813664555549622, 0.9813664555549622, 0.9689440727233887, 0.9813664555549622, 0.9689440727233887, 0.9627329111099243, 0.9751552939414978, 0.9813664555549622, 0.9813664555549622, 0.9813664555549622, 0.9192546606063843, 0.9689440727233887, 0.9689440727233887, 0.9813664555549622]
val_loss: [0.9879217743873596, 0.8109796047210693, 0.6925914883613586, 0.654873788356781, 0.6286959052085876, 0.5502739548683167, 0.5632897615432739, 0.5614997148513794, 0.5466619729995728, 0.48475366830825806, 0.40241432189941406, 0.3694719076156616, 0.3307814598083496, 0.30494406819343567, 0.32066893577575684, 0.31341293454170227, 0.2536642551422119, 0.6493536233901978, 0.25338971614837646, 0.33335304260253906, 0.34039658308029175, 0.26325535774230957, 0.20300377905368805, 0.29354923963546753, 0.2778205871582031, 0.2622685134410858, 0.17297233641147614, 0.19757412374019623, 0.17251381278038025, 0.22719831764698029, 0.15210989117622375, 0.15143246948719025, 0.17051120102405548, 0.14776694774627686, 0.1643703728914261, 0.11314480751752853, 0.13988526165485382, 0.11259517073631287, 0.12559916079044342, 0.17404867708683014, 0.12502314150333405, 0.13231807947158813, 0.13309510052204132, 0.10394690930843353, 0.10817369073629379, 0.09752959758043289, 0.12653350830078125, 0.10427632182836533, 0.11889635771512985, 0.1263289451599121, 0.12183570861816406, 0.1032046526670456, 0.11108352243900299, 0.11843433976173401, 0.3551219403743744, 0.1363908350467682, 0.15340390801429749, 0.11082330346107483]

Confusion Matrix:
[[71  4  0]
 [ 2 40  0]
 [ 0  1 43]]

################################################################################################ 

