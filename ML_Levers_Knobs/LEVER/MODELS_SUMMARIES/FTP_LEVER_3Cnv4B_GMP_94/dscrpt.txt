def build_branched_model2(input_shape1, input_shape2, input_shape3):
    # First input branch
    input1 = Input(shape=input_shape1, name='input1')
    x1 = Conv1D(filters=64, kernel_size=40, strides=20, activation='relu', padding='same', name='conv1d_1_1')(input1)
    x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_1')(x1)
    x1 = Conv1D(filters=128, kernel_size=8, strides=4, activation='relu', name='conv1d_1_2')(x1)
    x1 = Dropout(rate=0.2, name='dropout_1_1')(x1)
    x1 = Conv1D(filters=256, kernel_size=2, strides=1, activation='relu', name='conv1d_1_3')(x1)
    x1 = GlobalMaxPooling1D(name='gap1d_1_1')(x1)
    
    # Second input branch
    input2 = Input(shape=input_shape2, name='input2')
    x2 = Conv1D(filters=64, kernel_size=40, strides=20, activation='relu', padding='same', name='conv1d_2_1')(input2)
    x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=8, strides=4, activation='relu', name='conv1d_2_2')(x2)
    x2 = Dropout(rate=0.2, name='dropout_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_2_3')(x2)
    x2 = GlobalMaxPooling1D(name='gap1d_2_1')(x2)
    
    # Third input branch
    input3 = Input(shape=input_shape3, name='input3')
    x3 = Conv1D(filters=64, kernel_size=40, strides=20, activation='relu', padding='same', name='conv1d_3_1')(input3)
    x3 = MaxPooling1D(pool_size=2, name='maxpool1d_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=8, strides=4, activation='relu', name='conv1d_3_2')(x3)
    x3 = Dropout(rate=0.2, name='dropout_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_3_3')(x3)
    x3 = GlobalMaxPooling1D(name='gap1d_3_1')(x3)
    
    # Concatenate the outputs of the three branches
    merged = concatenate([x1, x2, x3], name='concatenate_1')
    
    # Dense layer
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    dense = Dense(32, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=[input1, input2, input3], outputs=output)
    return model

Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 2000, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 2000, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 100, 64)   │      5,184 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 100, 64)   │      2,624 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 100, 64)   │      2,624 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_1_1       │ (None, 50, 64)    │          0 │ conv1d_1_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_2_1       │ (None, 50, 64)    │          0 │ conv1d_2_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_3_1       │ (None, 50, 64)    │          0 │ conv1d_3_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 11, 128)   │     65,664 │ maxpool1d_1_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 11, 128)   │     65,664 │ maxpool1d_2_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 11, 128)   │     65,664 │ maxpool1d_3_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 11, 128)   │          0 │ conv1d_1_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 11, 128)   │          0 │ conv1d_2_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_3_1         │ (None, 11, 128)   │          0 │ conv1d_3_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 10, 256)   │     65,792 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 10, 128)   │     32,896 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 10, 128)   │     32,896 │ dropout_3_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 256)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 128)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 128)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 512)       │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │     32,832 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 32)        │      2,080 │ dense_1[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 3)         │         99 │ dense_2[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 1,122,059 (4.28 MB)
 Trainable params: 374,019 (1.43 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 748,040 (2.85 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x76de9c1a9a80>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.04138299450278282
Test val_loss: 0.13779112696647644
Train accuracy: 0.9854771494865417
Accuracy Score: 0.937888198757764
F1 Score: 0.9351408825093035
Classification Report:
               precision    recall  f1-score   support

         0.0       0.95      0.95      0.95        66
         1.0       0.96      0.90      0.93        59
         2.0       0.88      0.97      0.92        36

    accuracy                           0.94       161
   macro avg       0.93      0.94      0.94       161
weighted avg       0.94      0.94      0.94       161

Training History:
accuracy: [0.4294605851173401, 0.5041493773460388, 0.6576763391494751, 0.8423236608505249, 0.8236514329910278, 0.7863070368766785, 0.8672199249267578, 0.908713698387146, 0.9211618304252625, 0.8941908478736877, 0.8838174343109131, 0.9460580945014954, 0.9232364892959595, 0.9377593398094177, 0.9439833760261536, 0.8298755288124084, 0.865145206451416, 0.9336099624633789, 0.9585062265396118, 0.9709543585777283, 0.9688796401023865, 0.9668049812316895, 0.9688796401023865, 0.9709543585777283, 0.9771783947944641, 0.9688796401023865, 0.9771783947944641, 0.9751037359237671, 0.8734439611434937, 0.9315352439880371, 0.9668049812316895, 0.9730290174484253, 0.9668049812316895, 0.9834024906158447, 0.9709543585777283, 0.9813277721405029, 0.9626556038856506, 0.9709543585777283, 0.9792531132698059, 0.9730290174484253, 0.9771783947944641, 0.9896265268325806, 0.9854771494865417, 0.9751037359237671, 0.9813277721405029, 0.9854771494865417]
loss: [1.0468236207962036, 0.9711996912956238, 0.7767783999443054, 0.46945780515670776, 0.45414018630981445, 0.5801725387573242, 0.3824959397315979, 0.27361318469047546, 0.215301975607872, 0.26520782709121704, 0.2597607970237732, 0.21827790141105652, 0.33365917205810547, 0.2015836089849472, 0.16717401146888733, 0.43309929966926575, 0.29599201679229736, 0.20443271100521088, 0.14747180044651031, 0.10969559848308563, 0.1098921149969101, 0.10823570936918259, 0.0933285504579544, 0.09004339575767517, 0.07492226362228394, 0.09244676679372787, 0.07043016701936722, 0.08798877149820328, 0.36311954259872437, 0.1812705248594284, 0.11810724437236786, 0.09005163609981537, 0.08181583136320114, 0.06350485235452652, 0.06461725383996964, 0.07425255328416824, 0.09220670908689499, 0.0774521753191948, 0.05769064649939537, 0.06827209144830704, 0.05818263813853264, 0.03974694386124611, 0.046645428985357285, 0.05804523453116417, 0.048010069876909256, 0.04138299450278282]
val_accuracy: [0.4161490797996521, 0.3105590045452118, 0.6832298040390015, 0.6024844646453857, 0.9440993666648865, 0.7080745100975037, 0.8074533939361572, 0.850931704044342, 0.8012422323226929, 0.7639751434326172, 0.8757764101028442, 0.9006211161613464, 0.782608687877655, 0.9440993666648865, 0.9254658222198486, 0.9192546606063843, 0.9130434989929199, 0.9378882050514221, 0.8757764101028442, 0.8571428656578064, 0.9068322777748108, 0.9316770434379578, 0.95652174949646, 0.8757764101028442, 0.9192546606063843, 0.9503105878829956, 0.9627329111099243, 0.7701863646507263, 0.7888198494911194, 0.8571428656578064, 0.9068322777748108, 0.9130434989929199, 0.9192546606063843, 0.9627329111099243, 0.9316770434379578, 0.9503105878829956, 0.95652174949646, 0.8571428656578064, 0.9006211161613464, 0.9130434989929199, 0.8944099545478821, 0.9130434989929199, 0.9006211161613464, 0.9192546606063843, 0.9378882050514221, 0.95652174949646]
val_loss: [1.0350737571716309, 0.9825569987297058, 0.6571695804595947, 0.7628026008605957, 0.3370596468448639, 0.5799776911735535, 0.34472814202308655, 0.2676001191139221, 0.3430178761482239, 0.46219849586486816, 0.28373953700065613, 0.2887776792049408, 0.4576641023159027, 0.18324679136276245, 0.1956249326467514, 0.282726913690567, 0.2508775591850281, 0.22271233797073364, 0.289542019367218, 0.2970849871635437, 0.23543915152549744, 0.2254016399383545, 0.16674406826496124, 0.27361729741096497, 0.20773102343082428, 0.16584648191928864, 0.13640759885311127, 0.6032334566116333, 0.5868286490440369, 0.30788958072662354, 0.20624157786369324, 0.24605965614318848, 0.18721024692058563, 0.13628938794136047, 0.17878271639347076, 0.15486738085746765, 0.13883523643016815, 0.33072230219841003, 0.2588067948818207, 0.22464200854301453, 0.2511720657348633, 0.22240528464317322, 0.22490595281124115, 0.22313079237937927, 0.18869735300540924, 0.13779112696647644]

################################################################################################ 

