def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = np.dstack((data[:,:,2], data[:,:,4]))
        globals()[f"{key}2"] = np.dstack((data[:,:,0], data[:,:,2]))
        globals()[f"{key}3"] = data[:,:,5]
        globals()[f"{key}4"] = np.dstack((data[:,:,1], data[:,:,3]))
        
def build_branched_model(input_shapes):
    def create_branch(input_shape, branch_id):
        input_layer = Input(shape=input_shape, name=f'input{branch_id}')
        x = Conv1D(filters=128, kernel_size=400, strides=40, activation='relu', padding='same', name=f'conv1d_{branch_id}_1')(input_layer)
        #x = MaxPooling1D(pool_size=2)(x)
        x = Conv1D(filters=256, kernel_size=16, strides=2, activation='relu', name=f'conv1d_{branch_id}_2')(x)
        x = Conv1D(filters=256, kernel_size=8, strides=2, activation='relu', name=f'conv1d_{branch_id}_3')(x)
        #x = MaxPooling1D(pool_size=4)(x)
        x = Dropout(rate=0.25, name=f'dropout_{branch_id}_1')(x)
        x = Conv1D(filters=512, kernel_size=2, strides=1, activation='relu', name=f'conv1d_{branch_id}_4')(x)
        x = GlobalMaxPooling1D(name=f'gap1d_{branch_id}_1')(x)
        return input_layer, x

    inputs = []
    branches = []
    
    for i, input_shape in enumerate(input_shapes, 1):
        input_layer, branch_output = create_branch(input_shape, i)
        inputs.append(input_layer)
        branches.append(branch_output)
    
    merged = concatenate(branches, name='concatenate_1')
    
    # Dense layers
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=inputs, outputs=output)
    return model

Model: "functional_8"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 2000, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input4 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 50, 128)   │    102,528 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 50, 128)   │    102,528 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 50, 128)   │     51,328 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_1 (Conv1D) │ (None, 50, 128)   │    102,528 │ input4[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 18, 256)   │    524,544 │ conv1d_1_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 18, 256)   │    524,544 │ conv1d_2_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 18, 256)   │    524,544 │ conv1d_3_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_2 (Conv1D) │ (None, 18, 256)   │    524,544 │ conv1d_4_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 6, 256)    │    524,544 │ conv1d_1_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 6, 256)    │    524,544 │ conv1d_2_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 6, 256)    │    524,544 │ conv1d_3_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_3 (Conv1D) │ (None, 6, 256)    │    524,544 │ conv1d_4_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 6, 256)    │          0 │ conv1d_1_3[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 6, 256)    │          0 │ conv1d_2_3[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_3_1         │ (None, 6, 256)    │          0 │ conv1d_3_3[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_4_1         │ (None, 6, 256)    │          0 │ conv1d_4_3[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_4 (Conv1D) │ (None, 5, 512)    │    262,656 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_4 (Conv1D) │ (None, 5, 512)    │    262,656 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_4 (Conv1D) │ (None, 5, 512)    │    262,656 │ dropout_3_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_4 (Conv1D) │ (None, 5, 512)    │    262,656 │ dropout_4_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 512)       │          0 │ conv1d_1_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 512)       │          0 │ conv1d_2_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 512)       │          0 │ conv1d_3_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_4_1           │ (None, 512)       │          0 │ conv1d_4_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 2048)      │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0],  │
│                     │                   │            │ gap1d_4_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │    131,136 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 16)        │      1,040 │ dense_1[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 6)         │        102 │ dense_2[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 17,214,500 (65.67 MB)
 Trainable params: 5,738,166 (21.89 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 11,476,334 (43.78 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f0040144580>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.15364596247673035
Test val_loss: 0.5822781920433044
Train accuracy: 0.9554367065429688
Accuracy Score: 0.893048128342246
F1 Score: 0.8753062114391065
Classification Report:
               precision    recall  f1-score   support

         0.0       0.97      0.95      0.96        40
         1.0       0.90      0.87      0.89        54
         2.0       0.91      0.98      0.94        42
         3.0       0.82      1.00      0.90        14
         4.0       1.00      0.73      0.85        15
         5.0       0.70      0.73      0.71        22

    accuracy                           0.89       187
   macro avg       0.88      0.88      0.88       187
weighted avg       0.90      0.89      0.89       187

Training History:
accuracy: [0.3493761122226715, 0.5240641832351685, 0.5436720252037048, 0.5579322576522827, 0.5846702456474304, 0.6898396015167236, 0.7361853718757629, 0.7468805909156799, 0.7647058963775635, 0.7771835923194885, 0.8270944952964783, 0.8520498871803284, 0.8484848737716675, 0.8877005577087402, 0.8877005577087402, 0.8484848737716675, 0.8770053386688232, 0.866310179233551, 0.9286987781524658, 0.9180035591125488, 0.9144384860992432, 0.8966131806373596, 0.9215686321258545, 0.9215686321258545, 0.9286987781524658, 0.9197860956192017, 0.916221022605896, 0.916221022605896, 0.926916241645813, 0.9251337051391602, 0.9322637915611267, 0.9518716335296631, 0.9483066201210022, 0.9322637915611267, 0.9518716335296631, 0.9358288645744324, 0.9518716335296631, 0.9429590106010437, 0.9554367065429688]
loss: [1.7022558450698853, 1.2964413166046143, 1.2010654211044312, 1.1454169750213623, 1.0329893827438354, 0.8068373203277588, 0.7407082319259644, 0.6952601671218872, 0.5987557172775269, 0.6506592035293579, 0.4612480103969574, 0.427495539188385, 0.4419480860233307, 0.28515946865081787, 0.32069432735443115, 0.40285176038742065, 0.41012027859687805, 0.3421539068222046, 0.19913004338741302, 0.1956527829170227, 0.27167314291000366, 0.2859397232532501, 0.20210522413253784, 0.2049180269241333, 0.19155634939670563, 0.19675980508327484, 0.20385688543319702, 0.20570911467075348, 0.18000200390815735, 0.19527654349803925, 0.16778826713562012, 0.1619090437889099, 0.18109387159347534, 0.14818283915519714, 0.21003291010856628, 0.2409016489982605, 0.1681189388036728, 0.18021561205387115, 0.15364596247673035]
val_accuracy: [0.4064171016216278, 0.3957219123840332, 0.5347593426704407, 0.5133689641952515, 0.5508021116256714, 0.6470588445663452, 0.6310160160064697, 0.7112299203872681, 0.6363636255264282, 0.7058823704719543, 0.7112299203872681, 0.7647058963775635, 0.7860962748527527, 0.8235294222831726, 0.7219251394271851, 0.7433155179023743, 0.7700534462928772, 0.7967914342880249, 0.8609625697135925, 0.8181818127632141, 0.8502673506736755, 0.8716577291488647, 0.8395721912384033, 0.8716577291488647, 0.8770053386688232, 0.8235294222831726, 0.8770053386688232, 0.866310179233551, 0.855614960193634, 0.8823529481887817, 0.8449198007583618, 0.8877005577087402, 0.893048107624054, 0.9090909361839294, 0.866310179233551, 0.893048107624054, 0.8502673506736755, 0.8823529481887817, 0.8823529481887817]
val_loss: [1.5463989973068237, 1.5072367191314697, 1.2423650026321411, 1.3447132110595703, 1.0480554103851318, 1.004415512084961, 1.0479782819747925, 0.8857907652854919, 1.2168432474136353, 0.9540752172470093, 0.7370678782463074, 0.5285590887069702, 0.5918533802032471, 0.5947323441505432, 1.0589324235916138, 0.9099268913269043, 0.7255721688270569, 0.5330386757850647, 0.6393251419067383, 0.5905914306640625, 0.5125781297683716, 0.5562620759010315, 0.6629748344421387, 0.5756213068962097, 0.592074453830719, 0.6741269826889038, 0.4706498682498932, 0.5737450122833252, 0.6287928819656372, 0.5161881446838379, 0.6210899353027344, 0.6073458194732666, 0.5059576034545898, 0.4757888615131378, 0.5875399112701416, 0.5354410409927368, 0.5442463159561157, 0.5870179533958435, 0.5822781920433044]

################################################################################################ 

