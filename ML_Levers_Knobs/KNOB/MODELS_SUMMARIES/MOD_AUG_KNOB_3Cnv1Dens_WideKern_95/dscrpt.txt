def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = np.dstack((data[:,:,2], data[:,:,4]))
        globals()[f"{key}2"] = np.dstack((data[:,:,0], data[:,:,2]))
        globals()[f"{key}3"] = data[:,:,5]
        globals()[f"{key}4"] = np.dstack((data[:,:,1], data[:,:,3]))
        
def build_branched_model(input_shapes):
    def create_branch(input_shape, branch_id):
        input_layer = Input(shape=input_shape, name=f'input{branch_id}')
        x = Conv1D(filters=128, kernel_size=200, strides=40, activation='relu', padding='same', name=f'conv1d_{branch_id}_1')(input_layer)
        x = MaxPooling1D(pool_size=2)(x)
        #x = Conv1D(filters=128, kernel_size=8, strides=4, activation='relu', name=f'conv1d_{branch_id}_2')(x)
        x = Conv1D(filters=256, kernel_size=16, strides=2, activation='relu', name=f'conv1d_{branch_id}_3')(x)
        #x = MaxPooling1D(pool_size=4)(x)
        x = Dropout(rate=0.25, name=f'dropout_{branch_id}_1')(x)
        x = Conv1D(filters=512, kernel_size=2, strides=1, activation='relu', name=f'conv1d_{branch_id}_4')(x)
        x = GlobalMaxPooling1D(name=f'gap1d_{branch_id}_1')(x)
        return input_layer, x

    inputs = []
    branches = []
    
    for i, input_shape in enumerate(input_shapes, 1):
        input_layer, branch_output = create_branch(input_shape, i)
        inputs.append(input_layer)
        branches.append(branch_output)
    
    merged = concatenate(branches, name='concatenate_1')
    
    # Dense layers
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    #dense = Dense(32, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=inputs, outputs=output)
    return model

Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 2000, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input4 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 50, 128)   │     51,328 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 50, 128)   │     51,328 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 50, 128)   │     25,728 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_1 (Conv1D) │ (None, 50, 128)   │     51,328 │ input4[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_4     │ (None, 25, 128)   │          0 │ conv1d_1_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_5     │ (None, 25, 128)   │          0 │ conv1d_2_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_6     │ (None, 25, 128)   │          0 │ conv1d_3_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_7     │ (None, 25, 128)   │          0 │ conv1d_4_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 5, 256)    │    524,544 │ max_pooling1d_4[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 5, 256)    │    524,544 │ max_pooling1d_5[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 5, 256)    │    524,544 │ max_pooling1d_6[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_3 (Conv1D) │ (None, 5, 256)    │    524,544 │ max_pooling1d_7[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 5, 256)    │          0 │ conv1d_1_3[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 5, 256)    │          0 │ conv1d_2_3[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_3_1         │ (None, 5, 256)    │          0 │ conv1d_3_3[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_4_1         │ (None, 5, 256)    │          0 │ conv1d_4_3[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_4 (Conv1D) │ (None, 4, 512)    │    262,656 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_4 (Conv1D) │ (None, 4, 512)    │    262,656 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_4 (Conv1D) │ (None, 4, 512)    │    262,656 │ dropout_3_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_4 (Conv1D) │ (None, 4, 512)    │    262,656 │ dropout_4_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 512)       │          0 │ conv1d_1_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 512)       │          0 │ conv1d_2_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 512)       │          0 │ conv1d_3_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_4_1           │ (None, 512)       │          0 │ conv1d_4_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 2048)      │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0],  │
│                     │                   │            │ gap1d_4_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │    131,136 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 6)         │        390 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 10,380,116 (39.60 MB)
 Trainable params: 3,460,038 (13.20 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 6,920,078 (26.40 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7efffb53dc90>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.1207619458436966
Test val_loss: 0.327557772397995
Train accuracy: 0.9500890970230103
Accuracy Score: 0.946524064171123
F1 Score: 0.9397714356277976
Classification Report:
               precision    recall  f1-score   support

         0.0       0.97      0.97      0.97        40
         1.0       0.98      0.93      0.95        54
         2.0       0.97      0.93      0.95        42
         3.0       0.93      1.00      0.97        14
         4.0       0.93      0.87      0.90        15
         5.0       0.81      1.00      0.90        22

    accuracy                           0.95       187
   macro avg       0.93      0.95      0.94       187
weighted avg       0.95      0.95      0.95       187

Training History:
accuracy: [0.4331550896167755, 0.6666666865348816, 0.7754010558128357, 0.7397504448890686, 0.8199643492698669, 0.8360071182250977, 0.8680927157402039, 0.8573974967002869, 0.8948306441307068, 0.9019607901573181, 0.8948306441307068, 0.9197860956192017, 0.926916241645813, 0.9286987781524658, 0.9233511686325073, 0.9108734130859375, 0.9411764740943909, 0.9304812550544739, 0.9447415471076965, 0.9429590106010437, 0.9429590106010437, 0.9340463280677795, 0.9126559495925903, 0.9215686321258545, 0.9286987781524658, 0.9500890970230103, 0.9411764740943909, 0.9518716335296631, 0.9625668525695801, 0.9483066201210022, 0.9447415471076965, 0.9625668525695801, 0.9625668525695801, 0.9500890970230103]
loss: [1.40636146068573, 0.8853393197059631, 0.6064476370811462, 0.6128613352775574, 0.5006704330444336, 0.38432326912879944, 0.3473672866821289, 0.34712010622024536, 0.32336729764938354, 0.2730081379413605, 0.27682754397392273, 0.2411462366580963, 0.21139979362487793, 0.18725267052650452, 0.2191128134727478, 0.23971393704414368, 0.1720302700996399, 0.1918928325176239, 0.1454191952943802, 0.13488838076591492, 0.15929420292377472, 0.15500026941299438, 0.2090206742286682, 0.20504829287528992, 0.18350939452648163, 0.1386721283197403, 0.12966518104076385, 0.1287396401166916, 0.11280237138271332, 0.1596413105726242, 0.16041778028011322, 0.12519954144954681, 0.10207164287567139, 0.1207619458436966]
val_accuracy: [0.5133689641952515, 0.6844919919967651, 0.7058823704719543, 0.7540106773376465, 0.8288770318031311, 0.8235294222831726, 0.8502673506736755, 0.759358286857605, 0.866310179233551, 0.866310179233551, 0.8823529481887817, 0.855614960193634, 0.8983957171440125, 0.8770053386688232, 0.8609625697135925, 0.8395721912384033, 0.8823529481887817, 0.8770053386688232, 0.893048107624054, 0.8877005577087402, 0.8877005577087402, 0.903743326663971, 0.855614960193634, 0.866310179233551, 0.8877005577087402, 0.8877005577087402, 0.9197860956192017, 0.893048107624054, 0.9144384860992432, 0.9304812550544739, 0.8877005577087402, 0.8983957171440125, 0.9090909361839294, 0.9251337051391602]
val_loss: [1.3271899223327637, 0.7086307406425476, 0.7734764218330383, 0.9467249512672424, 0.43605107069015503, 0.45873916149139404, 0.39304226636886597, 0.7088790535926819, 0.4318951368331909, 0.41623741388320923, 0.3677224814891815, 0.36208289861679077, 0.33713576197624207, 0.3537859320640564, 0.3887053430080414, 0.5566594004631042, 0.3479430675506592, 0.30542469024658203, 0.3688013553619385, 0.30094441771507263, 0.34198713302612305, 0.25779157876968384, 0.5959133505821228, 0.38955751061439514, 0.43495097756385803, 0.39923095703125, 0.386969655752182, 0.35557448863983154, 0.38933584094047546, 0.3812740445137024, 0.3721623420715332, 0.46982526779174805, 0.3381526470184326, 0.327557772397995]

################################################################################################ 

