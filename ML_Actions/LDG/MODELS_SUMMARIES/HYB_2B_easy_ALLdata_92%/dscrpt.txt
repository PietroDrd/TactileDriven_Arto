def build_TwoBranchModel(F_input_shape, S_input_shape, num_classes):
    # 1D Data Branch
    input_1D = tf.keras.layers.Input(shape=F_input_shape, name='input_1D')
    conv1_1D = tf.keras.layers.Conv1D(64, kernel_size=40, strides=10, name='conv1_1D')(input_1D)
    conv1_1D = tf.keras.layers.Activation('relu')(conv1_1D)
    pool1_1D = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1_1D)

    conv2_1D = tf.keras.layers.Conv1D(128, kernel_size=4, strides=2, name='conv2_1D')(pool1_1D)
    conv2_1D = tf.keras.layers.Activation('relu')(conv2_1D)
    pool2_1D = tf.keras.layers.GlobalMaxPooling1D()(conv2_1D)

    flatten_1D = tf.keras.layers.Flatten()(pool2_1D)

    # 2D Data Branch (Scaleograms)
    input_2D = tf.keras.layers.Input(shape=S_input_shape, name='input_2D')
    conv1_2D = tf.keras.layers.Conv2D(64, kernel_size=(20, 20), strides=(10,10), padding='same', name='conv1_2D')(input_2D)
    conv1_2D = tf.keras.layers.Activation('relu')(conv1_2D)
    pool1_2D = tf.keras.layers.MaxPooling2D(pool_size=(4, 4))(conv1_2D)

    conv2_2D = tf.keras.layers.Conv2D(128, kernel_size=(10, 10), strides=(5,5), padding='same', name='conv2_2D')(pool1_2D)
    conv2_2D = tf.keras.layers.Activation('relu')(conv2_2D)
    pool2_2D = tf.keras.layers.GlobalMaxPooling2D()(conv2_2D)

    flatten_2D = tf.keras.layers.Flatten()(pool2_2D)

    # Merge branches
    merged = tf.keras.layers.concatenate([flatten_1D, flatten_2D])

    # Fully Connected Layers
    fc = tf.keras.layers.Dense(128, activation='relu')(merged)
    fc = tf.keras.layers.Dense(64, activation='relu')(fc)
    output = tf.keras.layers.Dense(num_classes, activation='softmax')(fc)

    # Define the Model
    model = tf.keras.Model(inputs=[input_1D, input_2D], outputs=output, name='TwoBranchModel')
    return model

Model: "TwoBranchModel"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_1D            │ (None, 3000, 9)   │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input_2D            │ (None, 3000, 768, │          0 │ -                 │
│ (InputLayer)        │ 1)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1_1D (Conv1D)   │ (None, 297, 64)   │     23,104 │ input_1D[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1_2D (Conv2D)   │ (None, 300, 77,   │     25,664 │ input_2D[0][0]    │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_4        │ (None, 297, 64)   │          0 │ conv1_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_6        │ (None, 300, 77,   │          0 │ conv1_2D[0][0]    │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_1     │ (None, 148, 64)   │          0 │ activation_4[0][… │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_1     │ (None, 75, 19,    │          0 │ activation_6[0][… │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2_1D (Conv1D)   │ (None, 73, 128)   │     32,896 │ max_pooling1d_1[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2_2D (Conv2D)   │ (None, 15, 4,     │    819,328 │ max_pooling2d_1[… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_5        │ (None, 73, 128)   │          0 │ conv2_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_7        │ (None, 15, 4,     │          0 │ conv2_2D[0][0]    │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 128)       │          0 │ activation_5[0][… │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 128)       │          0 │ activation_7[0][… │
│ (GlobalMaxPooling2… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ flatten_2 (Flatten) │ (None, 128)       │          0 │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ flatten_3 (Flatten) │ (None, 128)       │          0 │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 256)       │          0 │ flatten_2[0][0],  │
│ (Concatenate)       │                   │            │ flatten_3[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_3 (Dense)     │ (None, 128)       │     32,896 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_4 (Dense)     │ (None, 64)        │      8,256 │ dense_3[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_5 (Dense)     │ (None, 4)         │        260 │ dense_4[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,827,214 (10.78 MB)
 Trainable params: 942,404 (3.59 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,884,810 (7.19 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f7b1c5d7d30>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.14010222256183624
Test val_loss: 0.22186292707920074
Train accuracy: 0.9418604373931885
Accuracy Score: 0.9186046511627907
F1 Score: 0.9202124245924785
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00        17
         1.0       1.00      0.96      0.98        25
         2.0       0.77      1.00      0.87        23
         3.0       1.00      0.71      0.83        21

    accuracy                           0.92        86
   macro avg       0.94      0.92      0.92        86
weighted avg       0.94      0.92      0.92        86

Training History:
accuracy: [0.3449612259864807, 0.5503876209259033, 0.6356589198112488, 0.6356589198112488, 0.7713178396224976, 0.8449612259864807, 0.8449612259864807, 0.8449612259864807, 0.7635658979415894, 0.8837209343910217, 0.8837209343910217, 0.895348846912384, 0.9186046719551086, 0.9379844665527344, 0.8410852551460266, 0.9263566136360168, 0.9069767594337463, 0.8527131676673889, 0.856589138507843, 0.8527131676673889, 0.8372092843055725, 0.8372092843055725, 0.8720930218696594, 0.9418604373931885, 0.9418604373931885, 0.961240291595459, 0.9418604373931885]
loss: [1.5785971879959106, 1.0973944664001465, 0.9041847586631775, 0.8816853761672974, 0.5877789258956909, 0.42668312788009644, 0.32410669326782227, 0.3334425091743469, 0.5922589302062988, 0.284275084733963, 0.2670220136642456, 0.24035575985908508, 0.22047850489616394, 0.1847119927406311, 0.5263527035713196, 0.22189611196517944, 0.26582035422325134, 0.27419313788414, 0.3368159830570221, 0.422206312417984, 0.5860956907272339, 0.42658936977386475, 0.2994891405105591, 0.20482350885868073, 0.138170063495636, 0.11497469991445541, 0.14010222256183624]
val_accuracy: [0.5581395626068115, 0.45348837971687317, 0.7674418687820435, 0.6744186282157898, 0.6627907156944275, 0.7906976938247681, 0.6976743936538696, 0.8255813717842102, 0.8139534592628479, 0.8023256063461304, 0.8837209343910217, 0.8720930218696594, 0.930232584476471, 0.8488371968269348, 0.8720930218696594, 0.9186046719551086, 0.7790697813034058, 0.8604651093482971, 0.930232584476471, 0.8023256063461304, 0.8023256063461304, 0.8837209343910217, 0.8837209343910217, 0.895348846912384, 0.8837209343910217, 0.8720930218696594, 0.8837209343910217]
val_loss: [1.2579243183135986, 1.3777680397033691, 0.6241298913955688, 0.7137715816497803, 0.7340433597564697, 0.41613999009132385, 0.673128068447113, 0.3842889666557312, 0.4713326394557953, 0.42979106307029724, 0.27347615361213684, 0.25681260228157043, 0.20559293031692505, 0.41091784834861755, 0.2921295464038849, 0.2746165990829468, 0.5270811319351196, 0.4331030249595642, 0.16761206090450287, 0.45964476466178894, 0.6023174524307251, 0.289572149515152, 0.2364254593849182, 0.27255114912986755, 0.26301321387290955, 0.2837095856666565, 0.22186292707920074]

################################################################################################ 

