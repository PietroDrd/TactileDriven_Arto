def build_MultiBranchModel(input_shape1, input_shape2, input_shape3, input_shape4, num_classes):
    # Branch 1
    input1 = Input(shape=input_shape1, name='input1')
    x1 = Conv2D(64, kernel_size=(20, 20), strides=(10,10), activation='relu', padding='same')(input1)
    x1 = MaxPooling2D(pool_size=(2, 2))(x1)
    x1 = Conv2D(128, kernel_size=(2, 2), activation='relu', padding='same')(x1)
    x1 = GlobalMaxPooling2D()(x1)
    
    # Branch 2
    input2 = Input(shape=input_shape2, name='input2')
    x2 = Conv2D(64, kernel_size=(10, 10), strides=(5,5), activation='relu', padding='same')(input2)
    x2 = MaxPooling2D(pool_size=(2, 2))(x2)
    x2 = Conv2D(128, kernel_size=(4, 4), strides=(2,2), activation='relu', padding='same')(x2)
    #x2 = MaxPooling2D(pool_size=(2, 2))(x2)
    x2 = Conv2D(128, kernel_size=(2, 2), activation='relu', padding='same')(x2)
    x2 = GlobalMaxPooling2D()(x2)
    
    # Branch 3
    input3 = Input(shape=input_shape3, name='input3')
    x3 = Conv2D(64, kernel_size=(20, 20), strides=(10,10), activation='relu', padding='same')(input3)
    x3 = MaxPooling2D(pool_size=(2, 2))(x3)
    x3 = Conv2D(128, kernel_size=(2, 2), activation='relu', padding='same')(x3)
    x3 = GlobalMaxPooling2D()(x3)
    
    # Branch 4
    input4 = Input(shape=input_shape4, name='input4')
    x4 = Conv2D(64, kernel_size=(10, 10), strides=(5,5), activation='relu', padding='same')(input4)
    #x4 = MaxPooling2D(pool_size=(2, 2))(x4)
    x4 = Conv2D(128, kernel_size=(4, 4), strides=(2,2), activation='relu', padding='same')(x4)
    x4 = Conv2D(128, kernel_size=(2, 2), activation='relu', padding='same')(x4)
    x4 = GlobalMaxPooling2D()(x4)
    
    # Concatenate branches
    merged = Concatenate()([x1, x2, x3, x4])
    
    # Dense layers for classification
    dense = Dense(128, activation='relu')(merged)
    dense = Dropout(0.1)(dense)
    dense = Dense(64, activation='relu')(dense)
    output = Dense(OUT_N, activation='softmax')(dense)
    
    # Create model
    model = Model(inputs=[input1, input2, input3, input4], outputs=output)
    
    return model

Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input2 (InputLayer) │ (None, 3000, 128, │          0 │ -                 │
│                     │ 1)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input1 (InputLayer) │ (None, 3000, 128, │          0 │ -                 │
│                     │ 1)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_12 (Conv2D)  │ (None, 600, 26,   │      6,464 │ input2[0][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 3000, 256, │          0 │ -                 │
│                     │ 1)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input4 (InputLayer) │ (None, 3000, 256, │          0 │ -                 │
│                     │ 1)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_10 (Conv2D)  │ (None, 300, 13,   │     25,664 │ input1[0][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_4     │ (None, 300, 13,   │          0 │ conv2d_12[0][0]   │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_15 (Conv2D)  │ (None, 300, 26,   │     25,664 │ input3[0][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_17 (Conv2D)  │ (None, 600, 52,   │      6,464 │ input4[0][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_3     │ (None, 150, 6,    │          0 │ conv2d_10[0][0]   │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_13 (Conv2D)  │ (None, 150, 7,    │    131,200 │ max_pooling2d_4[… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_5     │ (None, 150, 13,   │          0 │ conv2d_15[0][0]   │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_18 (Conv2D)  │ (None, 300, 26,   │    131,200 │ conv2d_17[0][0]   │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_11 (Conv2D)  │ (None, 150, 6,    │     32,896 │ max_pooling2d_3[… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_14 (Conv2D)  │ (None, 150, 7,    │     65,664 │ conv2d_13[0][0]   │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_16 (Conv2D)  │ (None, 150, 13,   │     32,896 │ max_pooling2d_5[… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_19 (Conv2D)  │ (None, 300, 26,   │     65,664 │ conv2d_18[0][0]   │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 128)       │          0 │ conv2d_11[0][0]   │
│ (GlobalMaxPooling2… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 128)       │          0 │ conv2d_14[0][0]   │
│ (GlobalMaxPooling2… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 128)       │          0 │ conv2d_16[0][0]   │
│ (GlobalMaxPooling2… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 128)       │          0 │ conv2d_19[0][0]   │
│ (GlobalMaxPooling2… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 512)       │          0 │ global_max_pooli… │
│ (Concatenate)       │                   │            │ global_max_pooli… │
│                     │                   │            │ global_max_pooli… │
│                     │                   │            │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_3 (Dense)     │ (None, 128)       │     65,664 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1 (Dropout) │ (None, 128)       │          0 │ dense_3[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_4 (Dense)     │ (None, 64)        │      8,256 │ dropout_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_5 (Dense)     │ (None, 4)         │        260 │ dense_4[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 1,793,870 (6.84 MB)
 Trainable params: 597,956 (2.28 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,195,914 (4.56 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7effc8a5c250>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.1945163756608963
Test val_loss: 0.4673099219799042
Train accuracy: 0.9186046719551086
Accuracy Score: 0.9534883720930233
F1 Score: 0.9523809523809523
Classification Report:
               precision    recall  f1-score   support

         0.0       0.94      1.00      0.97        17
         1.0       1.00      1.00      1.00        25
         2.0       1.00      0.83      0.90        23
         3.0       0.88      1.00      0.93        21

    accuracy                           0.95        86
   macro avg       0.95      0.96      0.95        86
weighted avg       0.96      0.95      0.95        86

Training History:
accuracy: [0.38372093439102173, 0.643410861492157, 0.7829457521438599, 0.7170542478561401, 0.7906976938247681, 0.8023256063461304, 0.8604651093482971, 0.8992248177528381, 0.8837209343910217, 0.9069767594337463, 0.8837209343910217, 0.9069767594337463, 0.8643410801887512, 0.895348846912384, 0.9108527302742004, 0.9186046719551086]
loss: [1.4168610572814941, 0.9482043385505676, 0.6671921610832214, 0.5924779772758484, 0.5565797090530396, 0.46957167983055115, 0.34192290902137756, 0.3052465617656708, 0.2798978388309479, 0.22076416015625, 0.3528203070163727, 0.25337719917297363, 0.40408194065093994, 0.26102572679519653, 0.20995864272117615, 0.1945163756608963]
val_accuracy: [0.6744186282157898, 0.7558139562606812, 0.6162790656089783, 0.7209302186965942, 0.7790697813034058, 0.7906976938247681, 0.6860465407371521, 0.8604651093482971, 0.8488371968269348, 0.7906976938247681, 0.7674418687820435, 0.8720930218696594, 0.7558139562606812, 0.8255813717842102, 0.8372092843055725, 0.8255813717842102]
val_loss: [0.9872670769691467, 0.7181417346000671, 0.8587798476219177, 0.668483555316925, 0.4734061360359192, 0.38633400201797485, 0.8884316086769104, 0.3149425685405731, 0.37213653326034546, 0.7867621779441833, 0.661494255065918, 0.4203881621360779, 0.5561848282814026, 0.37585529685020447, 0.3442288637161255, 0.4673099219799042]

################################################################################################ 

