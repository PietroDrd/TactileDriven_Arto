Building Function:
def build_branched_model(input_shapes):
    def create_branch(input_shape, branch_id):
        input_layer = Input(shape=input_shape, name=f'input{branch_id}')
        x = Conv1D(filters=64*FILTN, kernel_size=40, strides=10, activation='relu', padding='same', name=f'conv1d_{branch_id}_1')(input_layer)
        x = Conv1D(filters=128*FILTN, kernel_size=8, strides=2, activation='relu', name=f'conv1d_{branch_id}_2')(x)
        x = Dropout(rate=0.25, name=f'dropout_{branch_id}_1')(x)
        x = Conv1D(filters=256*FILTN, kernel_size=2, strides=1, activation='relu', name=f'conv1d_{branch_id}_3')(x)
        x = GlobalMaxPooling1D(name=f'gap1d_{branch_id}_1')(x)
        return input_layer, x

    inputs = []
    branches = []
    
    for i, input_shape in enumerate(input_shapes, 1):
        input_layer, branch_output = create_branch(input_shape, i)
        inputs.append(input_layer)
        branches.append(branch_output)
    
    merged = concatenate(branches, name='concatenate_1')
    
    # Dense layers
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=inputs, outputs=output)
    return model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = np.dstack((data[:, :, 0], data[:, :, 4]))
        globals()[f"{key}2"] = np.dstack((data[:, :, 1], data[:, :, 3]))
        globals()[f"{key}3"] = np.dstack((data[:, :, 2],))
        # Uncomment and modify the line below if you need the fourth set
        # globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional_4"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 1800, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 180, 64)   │      5,184 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 180, 64)   │      5,184 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 180, 64)   │      2,624 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 87, 128)   │     65,664 │ conv1d_1_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 87, 128)   │     65,664 │ conv1d_2_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 87, 128)   │     65,664 │ conv1d_3_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 87, 128)   │          0 │ conv1d_1_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 87, 128)   │          0 │ conv1d_2_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_3_1         │ (None, 87, 128)   │          0 │ conv1d_3_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 86, 256)   │     65,792 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 86, 256)   │     65,792 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 86, 256)   │     65,792 │ dropout_3_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 256)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 256)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 256)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 768)       │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │     49,216 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 16)        │      1,040 │ dense_1[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 3)         │         51 │ dense_2[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 1,373,003 (5.24 MB)
 Trainable params: 457,667 (1.75 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 915,336 (3.49 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f4efc29e0b0>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.07305756956338882
Test val_loss: 0.5608630180358887
Train accuracy: 0.9700854420661926
Accuracy Score: 0.9808917197452229
F1 Score: 0.9807504185714017
Classification Report:
               precision    recall  f1-score   support

         0.0       0.98      0.98      0.98        47
         1.0       1.00      0.97      0.98        59
         2.0       0.96      1.00      0.98        51

    accuracy                           0.98       157
   macro avg       0.98      0.98      0.98       157
weighted avg       0.98      0.98      0.98       157

Training History:
accuracy: [0.4615384638309479, 0.561965823173523, 0.5790598392486572, 0.5683760643005371, 0.6004273295402527, 0.632478654384613, 0.7222222089767456, 0.7222222089767456, 0.7820512652397156, 0.8055555820465088, 0.8525640964508057, 0.8354700803756714, 0.8269230723381042, 0.8504273295402527, 0.8910256624221802, 0.9145299196243286, 0.8888888955116272, 0.9230769276618958, 0.9444444179534912, 0.9102563858032227, 0.8931623697280884, 0.9209401607513428, 0.9252136945724487, 0.9358974099159241, 0.942307710647583, 0.9209401607513428, 0.9166666865348816, 0.8995726704597473, 0.9294871687889099, 0.9465811848640442, 0.938034176826477, 0.9636752009391785, 0.9658119678497314, 0.9594017267227173, 0.9465811848640442, 0.9081196784973145, 0.94017094373703, 0.9487179517745972, 0.9615384340286255, 0.9337607026100159, 0.9529914259910583, 0.9594017267227173, 0.9529914259910583, 0.9615384340286255, 0.9679487347602844, 0.9700854420661926, 0.9700854420661926]
loss: [0.9951833486557007, 0.8818761110305786, 0.8968245387077332, 0.9045761227607727, 0.8495967984199524, 0.7831905484199524, 0.6498542428016663, 0.5908771753311157, 0.5187968015670776, 0.46772441267967224, 0.417636901140213, 0.4273408055305481, 0.42793676257133484, 0.3824860155582428, 0.3129070997238159, 0.26225146651268005, 0.28298261761665344, 0.21334218978881836, 0.20052063465118408, 0.24802982807159424, 0.2652450203895569, 0.2150851935148239, 0.1852482259273529, 0.1570378690958023, 0.14492245018482208, 0.20591239631175995, 0.23899462819099426, 0.24937015771865845, 0.19275474548339844, 0.1603732407093048, 0.14127473533153534, 0.11034554988145828, 0.09031116217374802, 0.1260252147912979, 0.14787325263023376, 0.2079448103904724, 0.16686102747917175, 0.12532353401184082, 0.09959442913532257, 0.1405247449874878, 0.1238880306482315, 0.11028682440519333, 0.09275178611278534, 0.097128726541996, 0.07978630065917969, 0.09268020838499069, 0.07305756956338882]
val_accuracy: [0.5833333134651184, 0.45512819290161133, 0.6666666865348816, 0.38461539149284363, 0.5, 0.5833333134651184, 0.7371794581413269, 0.692307710647583, 0.5705128312110901, 0.7756410241127014, 0.6089743375778198, 0.8461538553237915, 0.8141025900840759, 0.8012820482254028, 0.7820512652397156, 0.807692289352417, 0.8589743375778198, 0.8653846383094788, 0.807692289352417, 0.7179487347602844, 0.8205128312110901, 0.8717948794364929, 0.8653846383094788, 0.8717948794364929, 0.7371794581413269, 0.8333333134651184, 0.8910256624221802, 0.8141025900840759, 0.8653846383094788, 0.8846153616905212, 0.8846153616905212, 0.8782051205635071, 0.8461538553237915, 0.8653846383094788, 0.807692289352417, 0.7692307829856873, 0.9166666865348816, 0.8782051205635071, 0.9166666865348816, 0.8461538553237915, 0.8782051205635071, 0.8974359035491943, 0.8525640964508057, 0.8974359035491943, 0.8589743375778198, 0.8846153616905212, 0.8269230723381042]
val_loss: [0.8991789221763611, 1.0003888607025146, 0.8513398766517639, 1.1693875789642334, 0.8722864985466003, 0.8269037008285522, 0.6399599313735962, 0.633763313293457, 1.0158498287200928, 0.49317893385887146, 0.8011716604232788, 0.42150816321372986, 0.467876136302948, 0.42984887957572937, 0.5135502219200134, 0.4329531788825989, 0.36398035287857056, 0.36640629172325134, 0.4554519057273865, 0.6192962527275085, 0.4347057342529297, 0.3950454592704773, 0.3572832942008972, 0.3897073268890381, 0.725145697593689, 0.3991699516773224, 0.36137890815734863, 0.5152369737625122, 0.41272345185279846, 0.2919147312641144, 0.3267127275466919, 0.32290831208229065, 0.43653860688209534, 0.3557519316673279, 0.45943260192871094, 0.7520246505737305, 0.28725820779800415, 0.3234925866127014, 0.258629709482193, 0.41782814264297485, 0.27122506499290466, 0.2645185887813568, 0.3591766357421875, 0.31239503622055054, 0.3456245958805084, 0.2797364592552185, 0.5608630180358887]

Confusion Matrix:
[[46  0  1]
 [ 1 57  1]
 [ 0  0 51]]

################################################################################################ 

