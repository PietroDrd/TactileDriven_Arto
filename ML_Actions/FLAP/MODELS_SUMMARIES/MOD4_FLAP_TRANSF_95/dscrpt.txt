Building Function:
def build_branched_model(input_shapes):
    def create_branch(input_shape, branch_id):
        input_layer = Input(shape=input_shape, name=f'input{branch_id}')
        x = Conv1D(filters=128*FILTN, kernel_size=40, strides=10, activation='relu', padding='same', name=f'conv1d_{branch_id}_1')(input_layer)
        x = MaxPooling1D(pool_size=2)(x)
        x = Conv1D(filters=128*FILTN, kernel_size=8, strides=2, activation='relu', name=f'conv1d_{branch_id}_2')(x)
        #x = Dropout(rate=0.2, name=f'dropout_{branch_id}_1')(x)
        x = MaxPooling1D(pool_size=2)(x)
        x = Conv1D(filters=256*FILTN, kernel_size=2, strides=1, activation='relu', name=f'conv1d_{branch_id}_3')(x)
        x = GlobalMaxPooling1D(name=f'gap1d_{branch_id}_1')(x)
        return input_layer, x

    inputs = []
    branches = []
    
    for i, input_shape in enumerate(input_shapes, 1):
        input_layer, branch_output = create_branch(input_shape, i)
        inputs.append(input_layer)
        branches.append(branch_output)
    
    merged = concatenate(branches, name='concatenate_1')
    
    # Dense layers
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    #dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=inputs, outputs=output)
    return model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = data[:, :, 0]
        globals()[f"{key}2"] = data[:, :, 2]
        globals()[f"{key}3"] = np.dstack((data[:, :, 0], data[:, :, 4]))
        globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional_19"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 1800, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 1800, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input4 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 180, 256)  │     10,496 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 180, 256)  │     10,496 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 180, 256)  │     20,736 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_1 (Conv1D) │ (None, 180, 256)  │     20,736 │ input4[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_12    │ (None, 90, 256)   │          0 │ conv1d_1_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_14    │ (None, 90, 256)   │          0 │ conv1d_2_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_16    │ (None, 90, 256)   │          0 │ conv1d_3_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_18    │ (None, 90, 256)   │          0 │ conv1d_4_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 42, 256)   │    524,544 │ max_pooling1d_12… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 42, 256)   │    524,544 │ max_pooling1d_14… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 42, 256)   │    524,544 │ max_pooling1d_16… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_2 (Conv1D) │ (None, 42, 256)   │    524,544 │ max_pooling1d_18… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_13    │ (None, 21, 256)   │          0 │ conv1d_1_2[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_15    │ (None, 21, 256)   │          0 │ conv1d_2_2[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_17    │ (None, 21, 256)   │          0 │ conv1d_3_2[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_19    │ (None, 21, 256)   │          0 │ conv1d_4_2[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 20, 512)   │    262,656 │ max_pooling1d_13… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 20, 512)   │    262,656 │ max_pooling1d_15… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 20, 512)   │    262,656 │ max_pooling1d_17… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_3 (Conv1D) │ (None, 20, 512)   │    262,656 │ max_pooling1d_19… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 512)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 512)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 512)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_4_1           │ (None, 512)       │          0 │ conv1d_4_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 2048)      │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0],  │
│                     │                   │            │ gap1d_4_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │    131,136 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 3)         │        195 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 10,027,787 (38.25 MB)
 Trainable params: 3,342,595 (12.75 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 6,685,192 (25.50 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f0dfc2b06d0>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.0851956233382225
Test val_loss: 0.46459636092185974
Train accuracy: 0.9720497131347656
Accuracy Score: 0.9444444444444444
F1 Score: 0.9451682688397663
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.94      0.97        34
         1.0       0.93      0.95      0.94        40
         2.0       0.91      0.94      0.93        34

    accuracy                           0.94       108
   macro avg       0.95      0.94      0.95       108
weighted avg       0.95      0.94      0.94       108

Training History:
accuracy: [0.46894410252571106, 0.6894409656524658, 0.7857142686843872, 0.7732919454574585, 0.8198757767677307, 0.8664596080780029, 0.8167701959609985, 0.8291925191879272, 0.8322981595993042, 0.8664596080780029, 0.8136646151542664, 0.8633540272712708, 0.8913043737411499, 0.9285714030265808, 0.9161490797996521, 0.8167701959609985, 0.8819875717163086, 0.9472049474716187, 0.9378882050514221, 0.9285714030265808, 0.9130434989929199, 0.9316770434379578, 0.9596273303031921, 0.9720497131347656, 0.9720497131347656]
loss: [1.0516406297683716, 0.7248454093933105, 0.5492761731147766, 0.5712544322013855, 0.40106770396232605, 0.37306520342826843, 0.3919615149497986, 0.5114938020706177, 0.346855491399765, 0.3121200203895569, 0.48540249466896057, 0.32635319232940674, 0.2628776729106903, 0.19361138343811035, 0.23590505123138428, 0.49428391456604004, 0.3066880404949188, 0.17581027746200562, 0.1634083241224289, 0.22394713759422302, 0.23387297987937927, 0.1603616327047348, 0.1194077804684639, 0.10472970455884933, 0.0851956233382225]
val_accuracy: [0.5981308221817017, 0.6915887594223022, 0.6074766516685486, 0.8037382960319519, 0.8317757248878479, 0.7383177280426025, 0.8504672646522522, 0.8130841255187988, 0.8317757248878479, 0.8785046935081482, 0.7476635575294495, 0.7289719581604004, 0.8598130941390991, 0.9158878326416016, 0.8317757248878479, 0.822429895401001, 0.8878504633903503, 0.8130841255187988, 0.8598130941390991, 0.9252336621284485, 0.9065420627593994, 0.8785046935081482, 0.8971962332725525, 0.8878504633903503, 0.8317757248878479]
val_loss: [0.9045029878616333, 0.7381415963172913, 1.002751111984253, 0.6460618376731873, 0.6342121958732605, 0.6710798740386963, 0.5506652593612671, 0.5488439798355103, 0.5314843058586121, 0.4644649624824524, 0.5571481585502625, 0.7126585841178894, 0.4242333769798279, 0.38143256306648254, 0.42357927560806274, 0.506668210029602, 0.3710988461971283, 0.46424853801727295, 0.44885313510894775, 0.403430700302124, 0.4053003489971161, 0.4306532144546509, 0.3840753138065338, 0.4105658233165741, 0.46459636092185974]

Confusion Matrix:
[[32  1  1]
 [ 0 38  2]
 [ 0  2 32]]

################################################################################################ 

