def build_TwoBranchModel(F_input_shape, S_input_shape, num_classes):
    # 1D Data Branch
    input_1D = tf.keras.layers.Input(shape=F_input_shape, name='input_1D')
    conv1_1D = tf.keras.layers.Conv1D(64, kernel_size=40, strides=10, name='conv1_1D')(input_1D)
    conv1_1D = tf.keras.layers.Activation('relu')(conv1_1D)
    pool1_1D = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1_1D)

    conv2_1D = tf.keras.layers.Conv1D(128, kernel_size=8, strides=4, name='conv2_1D')(pool1_1D)
    conv2_1D = tf.keras.layers.Activation('relu')(conv2_1D)
    #pool2_1D = tf.keras.layers.GlobalMaxPooling1D()(conv2_1D)

    conv3_1D = tf.keras.layers.Conv1D(128, kernel_size=3, strides=1, name='conv3_1D')(conv2_1D)
    conv3_1D = tf.keras.layers.Activation('relu')(conv3_1D)
    pool3_1D = tf.keras.layers.GlobalMaxPooling1D()(conv3_1D)

    flatten_1D = tf.keras.layers.Flatten()(pool3_1D)

    # 2D Data Branch (Scaleograms)
    input_2D = tf.keras.layers.Input(shape=S_input_shape, name='input_2D')
    conv1_2D = tf.keras.layers.Conv2D(64, kernel_size=(20, 20), strides=(8,8), padding='same', name='conv1_2D')(input_2D)
    conv1_2D = tf.keras.layers.Activation('relu')(conv1_2D)
    pool1_2D = tf.keras.layers.MaxPooling2D(pool_size=(4, 4))(conv1_2D)

    conv2_2D = tf.keras.layers.Conv2D(128, kernel_size=(10, 10), strides=(5,5), padding='same', name='conv2_2D')(pool1_2D)
    conv2_2D = tf.keras.layers.Activation('relu')(conv2_2D)
    
    conv3_2D = tf.keras.layers.Conv2D(256, kernel_size=(4, 4), strides=(2,2), padding='same', name='conv3_2D')(conv2_2D)
    conv3_2D = tf.keras.layers.Activation('relu')(conv3_2D)
    pool3_2D = tf.keras.layers.GlobalMaxPooling2D()(conv3_2D)

    flatten_2D = tf.keras.layers.Flatten()(pool3_2D)

    # Merge branches
    merged = tf.keras.layers.concatenate([flatten_1D, flatten_2D])

    # Fully Connected Layers
    fc = tf.keras.layers.Dense(128, activation='relu')(merged)
    fc = tf.keras.layers.Dense(64, activation='relu')(fc)
    output = tf.keras.layers.Dense(num_classes, activation='softmax')(fc)

    # Define the Model
    model = tf.keras.Model(inputs=[input_1D, input_2D], outputs=output, name='TwoBranchModel')
    return model

Model: "TwoBranchModel"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_1D            │ (None, 1800, 9)   │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input_2D            │ (None, 1800, 768, │          0 │ -                 │
│ (InputLayer)        │ 1)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1_1D (Conv1D)   │ (None, 177, 64)   │     23,104 │ input_1D[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1_2D (Conv2D)   │ (None, 225, 96,   │     25,664 │ input_2D[0][0]    │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_6        │ (None, 177, 64)   │          0 │ conv1_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_9        │ (None, 225, 96,   │          0 │ conv1_2D[0][0]    │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_1     │ (None, 88, 64)    │          0 │ activation_6[0][… │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_1     │ (None, 56, 24,    │          0 │ activation_9[0][… │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2_1D (Conv1D)   │ (None, 21, 128)   │     65,664 │ max_pooling1d_1[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2_2D (Conv2D)   │ (None, 12, 5,     │    819,328 │ max_pooling2d_1[… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_7        │ (None, 21, 128)   │          0 │ conv2_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_10       │ (None, 12, 5,     │          0 │ conv2_2D[0][0]    │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv3_1D (Conv1D)   │ (None, 19, 128)   │     49,280 │ activation_7[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv3_2D (Conv2D)   │ (None, 6, 3, 256) │    524,544 │ activation_10[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_8        │ (None, 19, 128)   │          0 │ conv3_1D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_11       │ (None, 6, 3, 256) │          0 │ conv3_2D[0][0]    │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 128)       │          0 │ activation_8[0][… │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 256)       │          0 │ activation_11[0]… │
│ (GlobalMaxPooling2… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ flatten_2 (Flatten) │ (None, 128)       │          0 │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ flatten_3 (Flatten) │ (None, 256)       │          0 │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 384)       │          0 │ flatten_2[0][0],  │
│ (Concatenate)       │                   │            │ flatten_3[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_3 (Dense)     │ (None, 128)       │     49,280 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_4 (Dense)     │ (None, 64)        │      8,256 │ dense_3[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_5 (Dense)     │ (None, 4)         │        260 │ dense_4[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 4,696,142 (17.91 MB)
 Trainable params: 1,565,380 (5.97 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 3,130,762 (11.94 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7fe34823ee30>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.22112545371055603
Test val_loss: 0.2526647448539734
Train accuracy: 0.91756272315979
Accuracy Score: 0.978494623655914
F1 Score: 0.9761363636363636
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00        29
         1.0       1.00      1.00      1.00        22
         2.0       0.95      0.95      0.95        22
         3.0       0.95      0.95      0.95        20

    accuracy                           0.98        93
   macro avg       0.98      0.98      0.98        93
weighted avg       0.98      0.98      0.98        93

Training History:
accuracy: [0.26523298025131226, 0.5878136157989502, 0.7562723755836487, 0.7956989407539368, 0.7885304689407349, 0.7992831468582153, 0.8315412402153015, 0.8637992739677429, 0.8637992739677429, 0.8673835396766663, 0.8637992739677429, 0.8602150678634644, 0.8709677457809448, 0.9103942513465881, 0.91756272315979, 0.9247311949729919, 0.9498208165168762, 0.9354838728904724, 0.9247311949729919, 0.8924731016159058, 0.91756272315979, 0.9318996667861938, 0.9534050226211548, 0.9534050226211548, 0.9784946441650391, 0.9784946441650391, 0.9534050226211548, 0.9713261723518372, 0.9426523447036743, 0.91756272315979]
loss: [1.5141029357910156, 0.9338675141334534, 0.6482350826263428, 0.5364876389503479, 0.5656533241271973, 0.5226550102233887, 0.3740033507347107, 0.3152896463871002, 0.3496631383895874, 0.30410730838775635, 0.3462419807910919, 0.34448638558387756, 0.2944513261318207, 0.22078846395015717, 0.22681432962417603, 0.18120086193084717, 0.1408909410238266, 0.1286579817533493, 0.18211273849010468, 0.21054911613464355, 0.19049100577831268, 0.16305428743362427, 0.12122421711683273, 0.11364076286554337, 0.0790044292807579, 0.07395607233047485, 0.11891549080610275, 0.08055777102708817, 0.13461892306804657, 0.22112545371055603]
val_accuracy: [0.2795698940753937, 0.8494623899459839, 0.7204301357269287, 0.8709677457809448, 0.8172042965888977, 0.7419354915618896, 0.8924731016159058, 0.8387096524238586, 0.8494623899459839, 0.8602150678634644, 0.7849462628364563, 0.9139785170555115, 0.8709677457809448, 0.8817204236984253, 0.8924731016159058, 0.8817204236984253, 0.9139785170555115, 0.9247311949729919, 0.9139785170555115, 0.8602150678634644, 0.8817204236984253, 0.9139785170555115, 0.9032257795333862, 0.9032257795333862, 0.9032257795333862, 0.9247311949729919, 0.8817204236984253, 0.9139785170555115, 0.9354838728904724, 0.9139785170555115]
val_loss: [1.28660249710083, 0.5377446413040161, 0.6371534466743469, 0.30145877599716187, 0.4974924325942993, 0.4718191623687744, 0.2895815074443817, 0.4454635977745056, 0.4002491235733032, 0.35285505652427673, 0.5118165612220764, 0.24364303052425385, 0.32663777470588684, 0.3262682557106018, 0.3047412037849426, 0.24074871838092804, 0.22172406315803528, 0.2561986446380615, 0.32180729508399963, 0.4096399247646332, 0.336622953414917, 0.2064768224954605, 0.2511349022388458, 0.21687854826450348, 0.28296971321105957, 0.25249385833740234, 0.36423712968826294, 0.3365793228149414, 0.25300896167755127, 0.2526647448539734]

################################################################################################ 

