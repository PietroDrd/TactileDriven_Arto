Building Function:
def build_branched_model(input_shapes):
    def create_branch(input_shape, branch_id):
        input_layer = Input(shape=input_shape, name=f'input{branch_id}')
        x = Conv1D(filters=64*FILTN, kernel_size=100, strides=10, activation='relu', padding='same', name=f'conv1d_{branch_id}_1')(input_layer)
        x = Conv1D(filters=128*FILTN, kernel_size=4, strides=2, activation='relu', name=f'conv1d_{branch_id}_2')(x)
        # x = Dropout(rate=0.2, name=f'dropout_{branch_id}_1')(x)
        # x = Conv1D(filters=256*FILTN, kernel_size=2, strides=1, activation='relu', name=f'conv1d_{branch_id}_3')(x)
        x = GlobalMaxPooling1D(name=f'gap1d_{branch_id}_1')(x)
        return input_layer, x

    inputs = []
    branches = []
    
    for i, input_shape in enumerate(input_shapes, 1):
        input_layer, branch_output = create_branch(input_shape, i)
        inputs.append(input_layer)
        branches.append(branch_output)
    
    merged = concatenate(branches, name='concatenate_1')
    
    # Dense layers
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=inputs, outputs=output)
    return model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = np.dstack((data[:, :, 6], data[:, :, 8]))
        globals()[f"{key}2"] = np.dstack((data[:, :, 1], data[:, :, 5]))
        globals()[f"{key}3"] = np.dstack((data[:, :, 2], data[:, :, 4]))
        # Uncomment and modify the line below if you need the fourth set
        # globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 180, 128)  │     25,728 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 180, 128)  │     25,728 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 180, 128)  │     25,728 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 89, 256)   │    131,328 │ conv1d_1_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 89, 256)   │    131,328 │ conv1d_2_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 89, 256)   │    131,328 │ conv1d_3_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 256)       │          0 │ conv1d_1_2[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 256)       │          0 │ conv1d_2_2[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 256)       │          0 │ conv1d_3_2[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 768)       │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │     49,216 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 16)        │      1,040 │ dense_1[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 4)         │         68 │ dense_2[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 1,564,478 (5.97 MB)
 Trainable params: 521,492 (1.99 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,042,986 (3.98 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7fd96c309d80>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.21732904016971588
Test val_loss: 0.5105595588684082
Train accuracy: 0.9032257795333862
Accuracy Score: 0.946236559139785
F1 Score: 0.941340530814215
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.97      0.98        29
         1.0       0.91      0.95      0.93        22
         2.0       0.96      1.00      0.98        22
         3.0       0.89      0.85      0.87        20

    accuracy                           0.95        93
   macro avg       0.94      0.94      0.94        93
weighted avg       0.95      0.95      0.95        93

Training History:
accuracy: [0.40860214829444885, 0.6272401213645935, 0.7419354915618896, 0.8064516186714172, 0.8279569745063782, 0.856630802154541, 0.8387096524238586, 0.8673835396766663, 0.8924731016159058, 0.9103942513465881, 0.8673835396766663, 0.8853046298027039, 0.8888888955116272, 0.9103942513465881, 0.8996415734291077, 0.9032257795333862, 0.9426523447036743, 0.9211469292640686, 0.939068078994751, 0.91756272315979, 0.8853046298027039, 0.8458781242370605, 0.8853046298027039, 0.9032257795333862]
loss: [1.2776514291763306, 0.9369264245033264, 0.6498410105705261, 0.529005765914917, 0.448517382144928, 0.416427344083786, 0.4334433674812317, 0.3531128466129303, 0.27782389521598816, 0.24489052593708038, 0.29254069924354553, 0.2715676426887512, 0.2896781265735626, 0.20451754331588745, 0.23239554464817047, 0.2181161642074585, 0.1533280909061432, 0.18019311130046844, 0.15692569315433502, 0.20513243973255157, 0.24752140045166016, 0.36666780710220337, 0.25096169114112854, 0.21732904016971588]
val_accuracy: [0.6344085931777954, 0.5913978219032288, 0.7096773982048035, 0.7956989407539368, 0.8709677457809448, 0.8709677457809448, 0.8494623899459839, 0.8817204236984253, 0.8924731016159058, 0.8494623899459839, 0.8924731016159058, 0.8924731016159058, 0.9139785170555115, 0.8602150678634644, 0.9139785170555115, 0.9354838728904724, 0.8602150678634644, 0.8817204236984253, 0.8817204236984253, 0.9247311949729919, 0.9247311949729919, 0.8387096524238586, 0.8602150678634644, 0.8494623899459839]
val_loss: [1.0000232458114624, 0.7633765339851379, 0.7105345129966736, 0.4437685012817383, 0.3438388705253601, 0.38553619384765625, 0.36925673484802246, 0.29010632634162903, 0.27006471157073975, 0.3608458638191223, 0.3122325539588928, 0.2559509575366974, 0.22165466845035553, 0.4221060574054718, 0.18916618824005127, 0.17922040820121765, 0.30565109848976135, 0.30265775322914124, 0.2990177869796753, 0.25770604610443115, 0.2208555042743683, 0.44071561098098755, 0.5013298392295837, 0.5105595588684082]

Confusion Matrix:
[[28  0  0  1]
 [ 0 21  0  1]
 [ 0  0 22  0]
 [ 0  2  1 17]]

################################################################################################ 

